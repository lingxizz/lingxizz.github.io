{"meta":{"title":"lingxizz","subtitle":"","description":"just keep blogiing","author":"lingxizz","url":"https://lingxizz.github.io","root":"/"},"pages":[{"title":"","date":"2020-12-07T10:04:54.831Z","updated":"2020-12-07T10:04:54.831Z","comments":true,"path":"404.html","permalink":"https://lingxizz.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2020-12-07T10:05:00.114Z","updated":"2020-12-07T10:05:00.114Z","comments":true,"path":"about/index.html","permalink":"https://lingxizz.github.io/about/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2020-12-07T10:04:59.608Z","updated":"2020-12-07T10:04:59.608Z","comments":true,"path":"categories/index.html","permalink":"https://lingxizz.github.io/categories/index.html","excerpt":"","text":""},{"title":"frends","date":"2020-12-07T09:39:42.000Z","updated":"2020-12-07T10:04:59.606Z","comments":true,"path":"frends/index.html","permalink":"https://lingxizz.github.io/frends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-12-07T10:04:59.083Z","updated":"2020-12-07T10:04:59.083Z","comments":true,"path":"tags/index.html","permalink":"https://lingxizz.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"干货：计算机网络知识总结","date":"2020-12-07T10:05:18.749Z","updated":"2020-12-07T10:04:55.518Z","comments":true,"path":"2020/12/07/干货：计算机网络知识总结/","link":"","permalink":"https://lingxizz.github.io/2020/12/07/%E5%B9%B2%E8%B4%A7%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","excerpt":"","text":"1. 计算机概述 2. 物理层 3. 数据链路层 4. 网络层 5. 运输层 6. 应用层一计算机概述（1），基本术语 结点 （node）：网络中的结点可以是计算机，集线器，交换机或路由器等。 链路（link ）：从一个结点到另一个结点的一段物理线路。中间没有任何其他交点。 主机（host）：连接在因特网上的计算机. ISP（Internet Service Provider）：因特网服务提供者（提供商）. IXP（Internet eXchange Point）：互联网交换点IXP的主要作用就是允许两个网络直接相连并交换分组，而不需要再通过第三个网络来转发分组。. RFC(Request For Comments)意思是“请求评议”，包含了关于Internet几乎所有的重要的文字资料。 广域网WAN（Wide Area Network）任务是通过长距离运送主机发送的数据 城域网MAN（Metropolitan Area Network）用来将多个局域网进行互连 局域网LAN（Local Area Network）学校或企业大多拥有多个互连的局域网 个人区域网PAN（Personal Area Network）在个人工作的地方把属于个人使用的电子设备用无线技术连接起来的网络 端系统（end system）：处在因特网边缘的部分即是连接在因特网上的所有的主机. 分组（packet ）：因特网中传送的数据单元。由首部header和数据段组成。分组又称为包，首部可称为包头。 存储转发（store and forward ）:路由器收到一个分组，先存储下来，再检查其首部，查找转发表，按照首部中的目的地址，找到合适的接口转发出去。 带宽（bandwidth）：在计算机网络中，表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。常用来表示网络的通信线路所能传送数据的能力。单位是“比特每秒”，记为b/s。 吞吐量（throughput ）：表示在单位时间内通过某个网络（或信道、接口）的数据量。吞吐量更经常地用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。吞吐量受网络的带宽或网络的额定速率的限制。（2），重要知识点总结 1，计算机网络（简称网络）把许多计算机连接在一起，而互联网把许多网络连接在一起，是网络的网络。 2，小写字母i开头的internet（互联网）是通用名词，它泛指由多个计算机网络相互连接而成的网络。在这些网络之间的通信协议（即通信规则）可以是任意的。 大写字母I开头的Internet（互联网）是专用名词，它指全球最大的，开放的，由众多网络相互连接而成的特定的互联网，并采用TCP/IP协议作为通信规则，其前身为ARPANET。Internet的推荐译名为因特网，现在一般流行称为互联网。 3，路由器是实现分组交换的关键构件，其任务是转发收到的分组，这是网络核心部分最重要的功能。分组交换采用存储转发技术，表示把一个报文（要发送的整块数据）分为几个分组后再进行传送。在发送报文之前，先把较长的报文划分成为一个个更小的等长数据段。在每个数据端的前面加上一些由必要的控制信息组成的首部后，就构成了一个分组。分组又称为包。分组是在互联网中传送的数据单元，正是由于分组的头部包含了诸如目的地址和源地址等重要控制信息，每一个分组才能在互联网中独立的选择传输路径，并正确地交付到分组传输的终点。 4，互联网按工作方式可划分为边缘部分和核心部分。主机在网络的边缘部分，其作用是进行信息处理。由大量网络和连接这些网络的路由器组成核心部分，其作用是提供连通性和交换。 5，计算机通信是计算机中进程（即运行着的程序）之间的通信。计算机网络采用的通信方式是客户-服务器方式（C/S方式）和对等连接方式（P2P方式）。 6，客户和服务器都是指通信中所涉及的应用进程。客户是服务请求方，服务器是服务提供方。 7，按照作用范围的不同，计算机网络分为广域网WAN，城域网MAN，局域网LAN，个人区域网PAN。 8，计算机网络最常用的性能指标是：速率，带宽，吞吐量，时延（发送时延，处理时延，排队时延），时延带宽积，往返时间和信道利用率。 9，网络协议即协议，是为进行网络中的数据交换而建立的规则。计算机网络的各层以及其协议集合，称为网络的体系结构。 10，五层体系结构由应用层，运输层，网络层（网际层），数据链路层，物理层组成。运输层最主要的协议是TCP和UDP协议，网络层最重要的协议是IP协议。 二物理层（1），基本术语数据（data）：运送消息的实体。信号（signal）：数据的电气的或电磁的表现。或者说信号是适合在传输介质上传输的对象。码元（ code）： 在使用时间域（或简称为时域）的波形来表示数字信号时，代表不同离散数值的基本波形。单工（simplex ）：只能有一个方向的通信而没有反方向的交互。半双工（half duplex ）：通信的双方都可以发送信息，但不能双方同时发送(当然也就不能同时接收)。全双工（full duplex）： 通信的双方可以同时发送和接收信息。奈氏准则：在任何信道中，码元的传输的效率是有上限的，传输速率超过此上限，就会出现严重的码间串扰问题，使接收端对码元的判决（即识别）成为不可能。基带信号（baseband signal）：来自信源的信号。指没有经过调制的数字信号或模拟信号。 带通（频带）信号（bandpass signal）：把基带信号经过载波调制后，把信号的频率范围搬移到较高的频段以便在信道中传输（即仅在一段频率范围内能够通过信道），这里调制过后的信号就是带通信号。 调制（modulation ）：对信号源的信息进行处理后加到载波信号上，使其变为适合在信道传输的形式的过程。信噪比（signal-to-noise ratio ）：指信号的平均功率和噪声的平均功率之比，记为S/N。信噪比（dB）=10*log10（S/N）信道复用（channel multiplexing ）：指多个用户共享同一个信道。（并不一定是同时）比特率（bit rate ）：单位时间（每秒）内传送的比特数。波特率（baud rate）：单位时间载波调制状态改变的次数。针对数据信号对载波的调制速率。复用（multiplexing）：共享信道的方法ADSL（Asymmetric Digital Subscriber Line ）： 非对称数字用户线。光纤同轴混合网（HFC网）:在目前覆盖范围很广的有线电视网的基础上开发的一种居民宽带接入网（2），重要知识点总结 1，物理层的主要任务就是确定与传输媒体接口有关的一些特性，如机械特性，电气特性，功能特性，过程特性。 2，一个数据通信系统可划分为三大部分，即源系统，传输系统，目的系统。源系统包括源点（或源站，信源）和发送器，目的系统包括接收器和终点。 3，通信的目的是传送消息。如话音，文字，图像等都是消息，数据是运送消息的实体。信号则是数据的电器或电磁的表现。 4，根据信号中代表消息的参数的取值方式不同，信号可分为模拟信号（或连续信号）和数字信号（或离散信号）。在使用时间域（简称时域）的波形表示数字信号时，代表不同离散数值的基本波形称为码元。 5，根据双方信息交互的方式，通信可划分为单向通信（或单工通信），双向交替通信（或半双工通信），双向同时通信（全双工通信）。 6，来自信源的信号称为基带信号。信号要在信道上传输就要经过调制。调制有基带调制和带通调制之分。最基本的带通调制方法有调幅，调频和调相。还有更复杂的调制方法，如正交振幅调制。 7，要提高数据在信道上的传递速率，可以使用更好的传输媒体，或使用先进的调制技术。但数据传输速率不可能任意被提高。 8，传输媒体可分为两大类，即导引型传输媒体（双绞线，同轴电缆，光纤）和非导引型传输媒体（无线，红外，大气激光）。 9，为了有效利用光纤资源，在光纤干线和用户之间广泛使用无源光网络PON。无源光网络无需配备电源，其长期运营成本和管理成本都很低。最流行的无源光网络是以太网无源光网络EPON和吉比特无源光网络GPON。 （3），最重要的知识点①，物理层的任务 透明地传送比特流。也可以将物理层的主要任务描述为确定与传输媒体的接口的一些特性，即：机械特性（接口所用接线器的一些物理属性如形状尺寸），电气特性（接口电缆的各条线上出现的电压的范围），功能特性（某条线上出现的某一电平的电压的意义），过程特性（对于不同功能能的各种可能事件的出现顺序）。 拓展： 物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。现有的计算机网络中的硬件设备和传输媒体的种类非常繁多，而且通信手段也有许多不同的方式。物理层的作用正是尽可能地屏蔽掉这些传输媒体和通信手段的差异，使物理层上面的数据链路层感觉不到这些差异，这样就可以使数据链路层只考虑完成本层的协议和服务，而不必考虑网络的具体传输媒体和通信手段是什么。 ②，几种常用的信道复用技术 ③，几种常用的宽带接入技术，主要是ADSL和FTTx 用户到互联网的宽带接入方法有非对称数字用户线ADSL（用数字技术对现有的模拟电话线进行改造，而不需要重新布线。ASDL的快速版本是甚高速数字用户线VDSL。），光纤同轴混合网HFC（是在目前覆盖范围很广的有线电视网的基础上开发的一种居民宽带接入网）和FTTx（即光纤到······）。 三数据链路层（1），基本术语 链路（link）：一个结点到相邻结点的一段物理链路 数据链路（data link）：把实现控制数据运输的协议的硬件和软件加到链路上就构成了数据链路 循环冗余检验CRC（Cyclic Redundancy Check）：为了保证数据传输的可靠性，CRC是数据链路层广泛使用的一种检错技术 帧（frame）：一个数据链路层的传输单元，由一个数据链路层首部和其携带的封包所组成协议数据单元。 MTU（Maximum Transfer Uint ）：最大传送单元。帧的数据部分的的长度上限。 误码率BER（Bit Error Rate ）：在一段时间内，传输错误的比特占所传输比特总数的比率。 PPP（Point-to-Point Protocol ）：点对点协议。即用户计算机和ISP进行通信时所使用的数据链路层协议。以下是PPP帧的示意图: MAC地址（Media Access Control或者Medium Access Control）：意译为媒体访问控制，或称为物理地址、硬件地址，用来定义网络设备的位置。 在OSI模型中，第三层网络层负责 IP地址，第二层数据链路层则负责 MAC地址。 因此一个主机会有一个MAC地址，而每个网络位置会有一个专属于它的IP地址 。 地址是识别某个系统的重要标识符，“名字指出我们所要寻找的资源，地址指出资源所在的地方，路由告诉我们如何到达该处” 网桥（bridge）：一种用于数据链路层实现中继，连接两个或多个局域网的网络互连设备。 交换机（switch ）：广义的来说，交换机指的是一种通信系统中完成信息交换的设备。这里工作在数据链路层的交换机指的是交换式集线器，其实质是一个多接口的网桥（2），重要知识点总结1，链路是从一个结点到相邻节点的一段物理链路，数据链路则在链路的基础上增加了一些必要的硬件（如网络适配器）和软件（如协议的实现） 2，数据链路层使用的主要是点对点信道和广播信道两种。 3，数据链路层传输的协议数据单元是帧。数据链路层的三个基本问题是：封装成帧，透明传输和差错检测 4，循环冗余检验CRC是一种检错方法，而帧检验序列FCS是添加在数据后面的冗余码 5，点对点协议PPP是数据链路层使用最多的一种协议，它的特点是：简单，只检测差错而不去纠正差错，不使用序号，也不进行流量控制，可同时支持多种网络层协议 6，PPPoE是为宽带上网的主机使用的链路层协议 7，局域网的优点是：具有广播功能，从一个站点可方便地访问全网；便于系统的扩展和逐渐演变；提高了系统的可靠性，可用性和生存性。 8，共向媒体通信资源的方法有二：一是静态划分信道(各种复用技术)，而是动态媒体接入控制，又称为多点接入（随即接入或受控接入） 9，计算机与外接局域网通信需要通过通信适配器（或网络适配器），它又称为网络接口卡或网卡。计算器的硬件地址就在适配器的ROM中。 10，以太网采用的无连接的工作方式，对发送的数据帧不进行编号，也不要求对方发回确认。目的站收到有差错帧就把它丢掉，其他什么也不做 11，以太网采用的协议是具有冲突检测的载波监听多点接入CSMA/CD。协议的特点是：发送前先监听，边发送边监听，一旦发现总线上出现了碰撞，就立即停止发送。然后按照退避算法等待一段随机时间后再次发送。 因此，每一个站点在自己发送数据之后的一小段时间内，存在这遭遇碰撞的可能性。以太网上的各站点平等的争用以太网信道 12，以太网的适配器具有过滤功能，它只接收单播帧，广播帧和多播帧。 13，使用集线器可以在物理层扩展以太网（扩展后的以太网仍然是一个网络） （3），最重要的知识点① 数据链路层的点对点信道和广播信道的特点，以及这两种信道所使用的协议（PPP协议以及CSMA/CD协议）的特点② 数据链路层的三个基本问题：封装成帧，透明传输，差错检测③ 以太网的MAC层硬件地址④ 适配器，转发器，集线器，网桥，以太网交换机的作用以及适用场合四网络层（1），基本术语虚电路（Virtual Circuit）：在两个终端设备的逻辑或物理端口之间，通过建立的双向的透明传输通道。虚电路表示这只是一条逻辑上的连接，分组都沿着这条逻辑连接按照存储转发方式传送，而并不是真正建立了一条物理连接。IP（Internet Protocol ）：网际协议 IP 是 TCP/IP体系中两个最主要的协议之一，是TCP/IP体系结构网际层的核心。配套的有ARP，RARP，ICMP，IGMP。 ARP（Address Resolution Protocol）：地址解析协议ICMP（Internet Control Message Protocol ）：网际控制报文协议 （ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。）子网掩码（subnet mask ）：它是一种用来指明一个IP地址的哪些位标识的是主机所在的子网以及哪些位标识的是主机的位掩码。子网掩码不能单独存在，它必须结合IP地址一起使用。 CIDR（ Classless Inter-Domain Routing ）：无分类域间路由选择 （特点是消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，并使用各种长度的“网络前缀”(network-prefix)来代替分类地址中的网络号和子网号）默认路由（default route）：当在路由表中查不到能到达目的地址的路由时，路由器选择的路由。默认路由还可以减小路由表所占用的空间和搜索路由表所用的时间。路由选择算法（Virtual Circuit）：路由选择协议的核心部分。因特网采用自适应的，分层次的路由选择协议。（2），重要知识点总结1，TCP/IP协议中的网络层向上只提供简单灵活的，无连接的，尽最大努力交付的数据报服务。网络层不提供服务质量的承诺，不保证分组交付的时限所传送的分组可能出错，丢失，重复和失序。进程之间通信的可靠性由运输层负责 2，在互联网的交付有两种，一是在本网络直接交付不用经过路由器，另一种是和其他网络的间接交付，至少经过一个路由器，但最后一次一定是直接交付 3，分类的IP地址由网络号字段（指明网络）和主机号字段（指明主机）组成。网络号字段最前面的类别指明IP地址的类别。IP地址是一种分等级的地址结构。IP地址管理机构分配IP地址时只分配网络号，主机号由得到该网络号的单位自行分配。路由器根据目的主机所连接的网络号来转发分组。一个路由器至少连接到两个网络，所以一个路由器至少应当有两个不同的IP地址 4，IP数据报分为首部和数据两部分。首部的前一部分是固定长度，共20字节，是所有IP数据包必须具有的（源地址，目的地址，总长度等重要地段都固定在首部）。一些长度可变的可选字段固定在首部的后面。IP首部中的生存时间给出了IP数据报在互联网中所能经过的最大路由器数。可防止IP数据报在互联网中无限制的兜圈子。 5，地址解析协议ARP把IP地址解析为硬件地址。ARP的高速缓存可以大大减少网络上的通信量。因为这样可以使主机下次再与同样地址的主机通信时，可以直接从高速缓存中找到所需要的硬件地址而不需要再去广播方式发送ARP请求分组 6，无分类域间路由选择CIDR是解决目前IP地址紧缺的一个好办法。CIDR记法把IP地址后面加上斜线“/”，然后写上前缀所所占的位数。前缀（或网络前缀用来指明网络），前缀后面的部分是后缀，用来指明主机。CIDR把前缀都相同的连续的IP地址组成一个“CIDR地址块”，IP地址分配都以CIDR地址块为单位。 7， 网际控制报文协议是IP层的协议.ICMP报文作为IP数据报的数据，加上首部后组成IP数据报发送出去。使用ICMP数据报并不是为了实现可靠传输。ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告。ICMP报文的种类有两种 ICMP差错报告报文和ICMP询问报文。 8，要解决IP地址耗尽的问题，最根本的办法是采用具有更大地址空间的新版本IP协议-IPv6。IPv6所带来的变化有①更大的地址空间（采用128位地址）②灵活的首部格式③改进的选项④支持即插即用⑤支持资源的预分配⑥IPv6的首部改为8字节对齐。另外IP数据报的目的地址可以是以下三种基本类型地址之一：单播，多播和任播 9，虚拟专用网络VPN利用公用的互联网作为本机构专用网之间的通信载体。VPN内使用互联网的专用地址。一个VPN至少要有一个路由器具有合法的全球IP地址，这样才能和本系统的另一个VPN通过互联网进行通信。所有通过互联网传送的数据都需要加密 10， MPLS的特点是：①支持面向连接的服务质量②支持流量工程，平衡网络负载③有效的支持虚拟专用网VPN。MPLS在入口节点给每一个IP数据报打上固定长度的“标记”，然后根据标记在第二层（链路层）用硬件进行转发（在标记交换路由器中进行标记交换），因而转发速率大大加快。 （3），最重要知识点① 虚拟互联网络的概念② IP地址和物理地址的关系③ 传统的分类的IP地址（包括子网掩码）和无分类域间路由选择CIDR④ 路由选择协议的工作原理五运输层（1），基本术语进程（process）：指计算机中正在运行的程序实体应用进程互相通信：一台主机的进程和另一台主机中的一个进程交换数据的过程（另外注意通信真正的端点不是主机而是主机中的进程，也就是说端到端的通信是应用进程之间的通信）传输层的复用与分用：复用指发送方不同的进程都可以通过统一个运输层协议传送数据。分用指接收方的运输层在剥去报文的首部后能把这些数据正确的交付到目的应用进程。 TCP（Transmission Control Protocol）：传输控制协议UDP（User Datagram Protocol）：用户数据报协议端口（port）（link）：端口的目的是为了确认对方机器是那个进程在于自己进行交互，比如MSN和QQ的端口不同，如果没有端口就可能出现QQ进程和MSN交互错误。端口又称协议端口号。 停止等待协议（link）：指发送方每发送完一个分组就停止发送，等待对方确认，在收到确认之后在发送下一个分组。流量控制（link）：就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。拥塞控制（link）：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。（2），重要知识点总结1，运输层提供应用进程之间的逻辑通信，也就是说，运输层之间的通信并不是真正在两个运输层之间直接传输数据。运输层向应用层屏蔽了下面网络的细节（如网络拓补，所采用的路由选择协议等），它使应用进程之间看起来好像两个运输层实体之间有一条端到端的逻辑通信信道。 2，网络层为主机提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。 3，运输层的两个重要协议是用户数据报协议UDP和传输控制协议TCP。按照OSI的术语，两个对等运输实体在通信时传送的数据单位叫做运输协议数据单元TPDU（Transport Protocol Data Unit）。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为TCP报文段或UDP用户数据报。 4，UDP在传送数据之前不需要先建立连接，远地主机在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP确是一种最有效的工作方式。 TCP提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。由于TCP要提供可靠的，面向连接的传输服务，这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。 5，硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层各种协议进程与运输实体进行层间交互的一种地址。UDP和TCP的首部格式中都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够 根据其首部中的目的端口号把数据交付应用层的目的应用层。（两个进程之间进行通信不光要知道对方IP地址而且要知道对方的端口号(为了找到对方计算机中的应用进程)） 6，运输层用一个16位端口号标志一个端口。端口号只有本地意义，它只是为了标志计算机应用层中的各个进程在和运输层交互时的层间接口。在互联网的不同计算机中，相同的端口号是没有关联的。协议端口号简称端口。虽然通信的终点是应用进程，但只要把所发送的报文交到目的主机的某个合适端口，剩下的工作（最后交付目的进程）就由TCP和UDP来完成。 7，运输层的端口号分为服务器端使用的端口号（01023指派给熟知端口，102449151是登记端口号）和客户端暂时使用的端口号（49152~65535） 8，UDP的主要特点是①无连接②尽最大努力交付③面向报文④无拥塞控制⑤支持一对一，一对多，多对一和多对多的交互通信⑥首部开销小（只有四个字段：源端口，目的端口，长度和检验和） 9，TCP的主要特点是①面向连接②每一条TCP连接只能是一对一的③提供可靠交付④提供全双工通信⑤面向字节流 10，TCP用主机的IP地址加上主机上的端口号作为TCP连接的端点。这样的端点就叫做套接字（socket）或插口。套接字用（IP地址：端口号）来表示。每一条TCP连接唯一被通信两端的两个端点所确定。 11，停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 12，为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停下来等待对方确认。这样可使信道上一直有数据不间断的在传送。这种传输方式可以明显提高信道利用率。 13，停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续ARQ协议可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。 14，TCP报文段的前20个字节是固定的，后面有4n字节是根据需要增加的选项。因此，TCP首部的最小长度是20字节。 15，TCP使用滑动窗口机制。发送窗口里面的序号表示允许发送的序号。发送窗口后沿的后面部分表示已发送且已收到确认，而发送窗口前沿的前面部分表示不允许发送。发送窗口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口的前沿通常是不断向前移动的。一般来说，我们总是希望数据传输更快一些。但如果发送方把数据发送的过快，接收方就可能来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 16，在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 17，为了进行拥塞控制，TCP发送方要维持一个拥塞窗口cwnd的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 18，TCP的拥塞控制采用了四种算法，即慢开始，拥塞避免，快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理AQM），以减少网络拥塞的发生。 19，运输连接的三个阶段，即：连接建立，数据传送和连接释放。 20，主动发起TCP连接建立的应用进程叫做客户，而被动等待连接建立的应用进程叫做服务器。TCP连接采用三报文握手机制。服务器要确认用户的连接请求，然后客户要对服务器的确认进行确认。 21，TCP的连接释放采用四报文握手机制。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送时，则发送连接释放通知，对方确认后就完全关闭了TCP连接 （3），最重要的知识点① 端口和套接字的意义② 无连接UDP的特点③ 面向连接TCP的特点④ 在不可靠的网络上实现可靠传输的工作原理，停止等待协议和ARQ协议① TCP的滑动窗口，流量控制，拥塞控制和连接管理六应用层（1），基本术语 域名系统（DNS）：DNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。 通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。在RFC文档中RFC 2181对DNS有规范说明，RFC 2136对DNS的动态更新进行说明，RFC 2308对DNS查询的反向缓存进行说明。 文件传输协议（FTP）：FTP 是File TransferProtocol（文件传输协议）的英文简称，而中文简称为“文传协议”。用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。 基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议以传输文件。在FTP的使用当中，用户经常遇到两个概念：&quot;下载&quot;（Download）和&quot;上传&quot;（Upload）。 &quot;下载&quot;文件就是从远程主机拷贝文件至自己的计算机上；&quot;上传&quot;文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说，用户可通过客户机程序向（从）远程主机上传（下载）文件。 简单文件传输协议（TFTP）：TFTP（Trivial File Transfer Protocol,简单文件传输协议）是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。端口号为69。 远程终端协议（TELENET）：Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。 在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。 可以在本地就能控制服务器。要开始一个telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 万维网（WWW）：WWW是环球信息网的缩写，（亦作“Web”、“WWW”、“&apos;W3&apos;”，英文全称为“World Wide Web”），中文名字为“万维网”，&quot;环球网&quot;等，常简称为Web。分为Web客户端和Web服务器程序。 WWW可以让Web客户端（常用浏览器）访问浏览Web服务器上的页面。是一个由许多互相链接的超文本组成的系统，通过互联网访问。在这个系统中，每个有用的事物，称为一样“资源”；并且由一个全局“统一资源标识符”（URI）标识；这些资源通过超文本传输协议（Hypertext Transfer Protocol）传送给用户，而后者通过点击链接来获得资源。 万维网联盟（英语：World Wide Web Consortium，简称W3C），又称W3C理事会。1994年10月在麻省理工学院（MIT）计算机科学实验室成立。万维网联盟的创建者是万维网的发明者蒂姆·伯纳斯-李。 万维网并不等同互联网，万维网只是互联网所能提供的服务其中之一，是靠着互联网运行的一项服务。 万维网的大致工作工程： 统一资源定位符（URL）：统一资源定位符是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。 超文本传输协议（HTTP）：超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。 设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。1960年美国人Ted Nelson构思了一种通过计算机处理文本信息的方法，并称之为超文本（hypertext）,这成为了HTTP超文本传输协议标准架构的发展根基。 代理服务器（Proxy Server）：代理服务器（Proxy Server）是一种网络实体，它又称为万维网高速缓存。 代理服务器把最近的一些请求和响应暂存在本地磁盘中。当新请求到达时，若代理服务器发现这个请求与暂时存放的的请求相同，就返回暂存的响应，而不需要按URL的地址再次去互联网访问该资源。 代理服务器可在客户端或服务器工作，也可以在中间系统工作。 http请求头：http请求头，HTTP客户程序（例如浏览器），向服务器发送请求的时候必须指明请求类型（一般是GET或者POST）。如有必要，客户程序还可以选择发送其他的请求头。 - Accept：浏览器可接受的MIME类型。 - Accept-Charset：浏览器可接受的字符集。 - Accept-Encoding：浏览器能够进行解码的数据编码方式，比如gzip。Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面。许多情形下这可以减少5到10倍的下载时间。 - Accept-Language：浏览器所希望的语言种类，当服务器能够提供一种以上的语言版本时要用到。 - Authorization：授权信息，通常出现在对服务器发送的WWW-Authenticate头的应答中。 - Connection：表示是否需要持久连接。如果Servlet看到这里的值为“Keep-Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点，Servlet需要在应答中发送一个Content-Length头，最简单的实现方法是：先把内容写入ByteArrayOutputStream，然后在正式写出内容之前计算它的大小。 - Content-Length：表示请求消息正文的长度。 - Cookie：这是最重要的请求头信息之一 - From：请求发送者的email地址，由一些特殊的Web客户程序使用，浏览器不会用到它。 - Host：初始URL中的主机和端口。 - If-Modified-Since：只有当所请求的内容在指定的日期之后又经过修改才返回它，否则返回304“Not Modified”应答。 - Pragma：指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝。 - Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。 - User-Agent：浏览器类型，如果Servlet返回的内容与浏览器类型有关则该值非常有用。简单邮件传输协议(SMTP)：SMTP（Simple Mail Transfer Protocol）即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。 SMTP协议属于TCP/IP协议簇，它帮助每台计算机在发送或中转信件时找到下一个目的地。 通过SMTP协议所指定的服务器,就可以把E-mail寄到收信人的服务器上了，整个过程只要几分钟。SMTP服务器则是遵循SMTP协议的发送邮件服务器，用来发送或中转发出的电子邮件。搜索引擎：搜索引擎（Search Engine）是指根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。 搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。全文索引： 全文索引技术是目前搜索引擎的关键技术。 试想在1M大小的文件中搜索一个词，可能需要几秒，在100M的文件中可能需要几十秒，如果在更大的文件中搜索那么就需要更大的系统开销，这样的开销是不现实的。 所以在这样的矛盾下出现了全文索引技术，有时候有人叫倒排文档技术。目录索引：目录索引（ search index/directory)，顾名思义就是将网站分门别类地存放在相应的目录中，因此用户在查询信息时，可选择关键词搜索，也可按分类目录逐层查找。垂直搜索引擎：垂直搜索引擎是针对某一个行业的专业搜索引擎，是搜索引擎的细分和延伸，是对网页库中的某类专门的信息进行一次整合，定向分字段抽取出需要的数据进行处理后再以某种形式返回给用户。 垂直搜索是相对通用搜索引擎的信息量大、查询不准确、深度不够等提出来的新的搜索引擎服务模式，通过针对某一特定领域、某一特定人群或某一特定需求提供的有一定价值的信息和相关服务。 其特点就是“专、精、深”，且具有行业色彩，相比较通用搜索引擎的海量信息无序化，垂直搜索引擎则显得更加专注、具体和深入。（2），重要知识点总结1，文件传输协议（FTP）使用TCP可靠的运输服务。FTP使用客户服务器方式。一个FTP服务器进程可以同时为多个用户提供服务。在进进行文件传输时，FTP的客户和服务器之间要先建立两个并行的TCP连接:控制连接和数据连接。实际用于传输文件的是数据连接。 2，万维网客户程序与服务器之间进行交互使用的协议是超文本传输协议HTTP。HTTP使用TCP连接进行可靠传输。但HTTP本身是无连接、无状态的。HTTP/1.1协议使用了持续连接（分为非流水线方式和流水线方式） 3，电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中，收件人可随时上网到自己使用的邮件服务器读取，相当于电子邮箱。 4，一个电子邮件系统有三个重要组成构件：用户代理、邮件服务器、邮件协议（包括邮件发送协议，如SMTP，和邮件读取协议，如POP3和IMAP）。用户代理和邮件服务器都要运行这些协议。 （3），最重要知识点总结① 域名系统-从域名解析出IP地址② 访问一个网站大致的过程③ 系统调用和应用编程接口概念","categories":[],"tags":[]},{"title":"Linux性能分析工具合集","slug":"Linux性能分析工具合集","date":"2020-06-29T16:00:00.000Z","updated":"2020-12-07T10:04:55.228Z","comments":true,"path":"2020/06/30/Linux性能分析工具合集/","link":"","permalink":"https://lingxizz.github.io/2020/06/30/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E5%90%88%E9%9B%86/","excerpt":"","text":"Linux性能分析工具合集 本文由读者投稿，原文地址：https://ysshao.cn/Linux/Linux_performance/ 。 1. 背景有时候会遇到一些疑难杂症，并且监控插件并不能一眼立马发现问题的根源。这时候就需要登录服务器进一步深入分析问题的根源。那么分析问题需要有一定的技术经验积累，并且有些问题涉及到的领域非常广，才能定位到问题。所以，分析问题和踩坑是非常锻炼一个人的成长和提升自我能力。如果我们有一套好的分析工具，那将是事半功倍，能够帮助大家快速定位问题，节省大家很多时间做更深入的事情。 2. 说明本篇文章主要介绍各种问题定位的工具以及会结合案例分析问题。 3. 分析问题的方法论套用5W2H方法，可以提出性能分析的几个问题 What-现象是什么样的 When-什么时候发生 Why-为什么会发生 Where-哪个地方发生的问题 How much-耗费了多少资源 How to do-怎么解决问题 4.性能分析工具合集 CPU针对应用程序，我们通常关注的是内核CPU调度器功能和性能。 线程的状态分析主要是分析线程的时间用在什么地方，而线程状态的分类一般分为： a. on-CPU：执行中，执行中的时间通常又分为用户态时间user和系统态时间sys。 b. off-CPU：等待下一轮上CPU，或者等待I/O、锁、换页等等，其状态可以细分为可执行、匿名换页、睡 眠、锁、空闲等状态。 分析工具 工具 描述 uptime/w 查看服务器运行时间、平均负载 top 监控每个进程的CPU用量分解 vmstat 系统的CPU平均负载情况 mpstat 查看多核CPU信息 sar -u 查看CPU过去或未来时点CPU利用率 pidstat 查看每个进程的用量分解 uptimeuptime 命令可以用来查看服务器已经运行了多久，当前登录的用户有多少，以及服务器在过去的1分钟、5分钟、15分钟的系统平均负载值 第一项是当前时间，up 表示系统正在运行，6:47是系统启动的总时间，最后是系统的负载load信息 w 同上，增加了具体登陆了那些用户及登陆时间。 top常用来监控Linux的系统状况，比如cpu、内存的使用，显示系统上正在运行的进程。 系统运行时间和平均负载： top命令的顶部显示与uptime命令相似的输出。 这些字段显示： 当前时间 系统已运行的时间 当前登录用户的数量 相应最近5、10和15分钟内的平均负载。 任务 第二行显示的是任务或者进程的总结。进程可以处于不同的状态。这里显示了全部进程的数量。除此之外，还有正在运行、睡眠、停止、僵尸进程的数量（僵尸是一种进程的状态）。这些进程概括信息可以用’t’切换显示。 CPU状态 下一行显示的是CPU状态。 这里显示了不同模式下的所占CPU时间的百分比。这些不同的CPU时间表示: us, user： 运行(未调整优先级的) 用户进程的CPU时间 sy，system: 运行内核进程的CPU时间 ni，niced：运行已调整优先级的用户进程的CPU时间 wa，IO wait: 用于等待IO完成的CPU时间 hi：处理硬件中断的CPU时间 si: 处理软件中断的CPU时间 st：这个虚拟机被hypervisor偷去的CPU时间（译注：如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的）。 内存使用 接下来两行显示内存使用率，有点像’free’命令。第一行是物理内存使用，第二行是虚拟内存使用(交换空间)。 物理内存显示如下:全部可用内存、已使用内存、空闲内存、缓冲内存。相似地：交换部分显示的是：全部、已使用、空闲和缓冲交换空间。 这里要说明的是不能用windows的内存概念理解这些数据，如果按windows的方式此台服务器“危矣”：8G的内存总量只剩下530M的可用内存。Linux的内存管理有其特殊性，复杂点需要一本书来说明，这里只是简单说点和我们传统概念（windows）的不同。 第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。 如果出于习惯去计算可用内存数，这里有个近似的计算公式： ​ 第四行的free + 第四行的buffers + 第五行的cached。 对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 字段/列 进程的属性 属性含义 PID 进程ID，进程的唯一标识符 USER 进程所有者的实际用户名。 PR 进程的调度优先级。这个字段的一些值是’rt’。这意味这这些进程运行在实时态。 NI 进程的nice值（优先级）。越小的值意味着越高的优先级。 VIRT 进程使用的虚拟内存。 RES 驻留内存大小。驻留内存是任务使用的非交换物理内存大小。 SHR SHR是进程使用的共享内存。 S 这个是进程的状态。它有以下不同的值:D–不可中断的睡眠态、R–运行态、S–睡眠态、T–被跟踪或已停止、Z – 僵尸态 %CPU 自从上一次更新时到现在任务所使用的CPU时间百分比。 %MEM 进程使用的可用物理内存百分比。 TIME+ 任务启动后到现在所使用的全部CPU时间，精确到百分之一秒。 COMMAND 运行进程所使用的命令。 还有许多在默认情况下不会显示的输出，它们可以显示进程的页错误、有效组和组ID和其他更多的信息。 常用交互命令： ‘B’：一些重要信息会以加粗字体显示(高亮)。这个命令可以切换粗体显示。 ‘b’: ‘D’或’S‘: 你将被提示输入一个值（以秒为单位），它会以设置的值作为刷新间隔。如果你这里输入了1，top将会每秒刷新。 top默认为3秒刷新 ‘l’、‘t’、‘m’: 切换负载、任务、内存信息的显示，这会相应地切换顶部的平均负载、任务/CPU状态和内存信息的概况显示。 ‘z’ : 切换彩色显示 ‘x’ 或者 ‘y’ 切换高亮信息：’x’将排序字段高亮显示（纵列）；’y’将运行进程高亮显示（横行）。依赖于你的显示设置，你可能需要让输出彩色来看到这些高亮。 ‘u’: 特定用户的进程 ‘n’ 或 ‘#’: 任务的数量 ‘k’: 结束任务 命令行选项 top //每隔3秒显式所有进程的资源占用情况 top -u oracle -c //按照用户显示进程、并显示完整命令 top -d 2 //每隔2秒显式所有进程的资源占用情况 top -c //每隔3秒显式进程的资源占用情况，并显示进程的命令行参数(默认只有进程名) top -p 12345 -p 6789//每隔3秒显示pid是12345和pid是6789的两个进程的资源占用情况 top -d 2 -c -p 123456 //每隔2秒显示pid是12345的进程的资源使用情况，并显式该进程启动的命令行参数 top -n 设置显示多少次后就退出 补充 top命令是Linux上进行系统监控的首选命令，但有时候却达不到我们的要求，比如当前这台服务器，top监控有很大的局限性。这台服务器运行着websphere集群，有两个节点服务，就是【top视图 01】中的老大、老二两个java进程，top命令的监控最小单位是进程，所以看不到我关心的java线程数和客户连接数，而这两个指标是java的web服务非常重要的指标，通常我用ps和netstate两个命令来补充top的不足。 vmstat​ vmstat命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。 ​ 一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如: 每个参数的含义： Procs（进程） r: 运行队列中进程数量，这个值也可以判断是否需要增加CPU。（长期大于1） b 等待IO的进程数量。 Memory（内存） swpd 使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。 free 空闲物理内存大小。 buff 用作缓冲的内存大小。 cache 用作缓存的内存大小，如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小。 Swap si 每秒从交换区写到内存的大小，由磁盘调入内存。 so 每秒写入交换区的内存大小，由内存调入磁盘。 注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。因为linux总是先把内存用光. IO bi 每秒读取的块数 bo 每秒写入的块数 注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 system（系统） in 每秒中断数，包括时钟中断。 cs 每秒上下文切换数。 注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 CPU（以百分比表示） us 用户进程执行时间百分比(user time) us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time) sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa IO等待时间百分比 wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id 空闲时间百分比 mpstat​ mpstat是一个实时监控工具，主要报告与CPU相关统计信息,在多核心cpu系统中，不仅可以查看cpu平均信息，还可以查看指定cpu信息。 mpstat -P ALL //查看全部CPU的负载情况。 mpstat 2 5 //可指定间隔时间和次数。 CPU: 处理器编号。关键字all表示统计信息计算为所有处理器之间的平均值。 ％usr: 显示在用户级（应用程序）执行时发生的CPU利用率百分比。 ％nice: 显示以优先级较高的用户级别执行时发生的CPU利用率百分比。 ％sys: 显示在系统级（内核）执行时发生的CPU利用率百分比。请注意，这不包括维护硬件和软件的时间中断。 ％iowait: 显示系统具有未完成磁盘I / O请求的CPU或CPU空闲的时间百分比。 ％irq: 显示CPU或CPU用于服务硬件中断的时间百分比。 %soft: 显示CPU或CPU用于服务软件中断的时间百分比。 %steal: 显示虚拟CPU或CPU在管理程序为另一个虚拟处理器提供服务时非自愿等待的时间百分比。 %guest: 显示CPU或CPU运行虚拟处理器所花费的时间百分比。 sar系统活动情况报告，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等 CPU相关： sar -p （查看全天） sar -u 1 10 （1：每隔一秒，10：写入10次） CPU输出项-详细说明 CPU:all 表示统计信息为所有 CPU 的平均值。 %user:显示在用户级别(application)运行使用 CPU 总时间的百分比。 %nice:显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。 %system:在核心级别(kernel)运行所使用 CPU 总时间的百分比。 %iowait:显示用于等待I/O操作占用 CPU 总时间的百分比。 %steal:管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比。 %idle:显示 CPU 空闲时间占用 CPU 总时间的百分比。 pidstat用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况。 pidstat 和 pidstat -u -p ALL 是等效的。 pidstat 默认显示了所有进程的cpu使用率。 详细说明 PID：进程ID %usr：进程在用户空间占用cpu的百分比 %system：进程在内核空间占用cpu的百分比 %guest：进程在虚拟机占用cpu的百分比 %CPU：进程占用cpu的百分比 CPU：处理进程的cpu编号 Command：当前进程对应的命令 内存内存是为提高效率而生，实际分析问题的时候，内存出现问题可能不只是影响性能，而是影响服务或者引起其他问题。同样对于内存有些概念需要清楚： 主存 虚拟内存 常驻内存 地址空间 OOM 页缓存 缺页 换页 交换空间 交换 用户分配器libc、glibc、libmalloc和mtmalloc LINUX内核级SLUB分配器 分析工具 工具 描述 free 查看内存的使用情况 top 监控每个进程的内存使用情况 vmstat 虚拟内存统计信息 sar -r 查看内存 sar 查看CPU过去或未来时点CPU利用率 pidstat 查看每个进程的内存使用情况 freefree 命令显示系统内存的使用情况，包括物理内存、交换内存(swap)和内核缓冲区内存。 Mem 行(第二行)是内存的使用情况。 Swap 行(第三行)是交换空间的使用情况。 total 列显示系统总的可用物理内存和交换空间大小。 used 列显示已经被使用的物理内存和交换空间。 free 列显示还有多少物理内存和交换空间可用使用。 shared 列显示被共享使用的物理内存大小。 buff/cache 列显示被 buffer 和 cache 使用的物理内存大小。 available 列显示还可以被应用程序使用的物理内存大小。 常用命令： free free -g 以GB显示 free -m 以MB显示 free -h 自动转换展示 free -h -s 3 有时我们需要持续的观察内存的状况，此时可以使用 -s 选项并指定间隔的秒数 所以从应用程序的角度来说，available = free + buffer + cache 可用内存=系统free memory+buffers+cached。 top请参考上面top的详解 vmstat请参考上面vmstat的详解 sarsar -r #查看内存使用情况 详解： kbmemfree 空闲的物理内存大小 kbmemused 使用中的物理内存大小 %memused 物理内存使用率 kbbuffers 内核中作为缓冲区使用的物理内存大小，kbbuffers和kbcached:这两个值就是free命令中的buffer 和cache. kbcached 缓存的文件大小 kbcommit 保证当前系统正常运行所需要的最小内存，即为了确保内存不溢出而需要的最少内存（物理内存 +Swap分区） commt 这个值是kbcommit与内存总量（物理内存+swap分区）的一个百分比的值 pidstatpidstat -r 查看内存使用情况 pidstat将显示各活动进程的内存使用统计 PID：进程标识符 Minflt/s:任务每秒发生的次要错误，不需要从磁盘中加载页 Majflt/s:任务每秒发生的主要错误，需要从磁盘中加载页 VSZ：虚拟地址大小，虚拟内存的使用KB RSS：常驻集合大小，非交换区五里内存使用KB Command：task命令名 磁盘IO磁盘通常是计算机最慢的子系统，也是最容易出现性能瓶颈的地方，因为磁盘离 CPU 距离最远而且 CPU 访问磁盘要涉及到机械操作，比如转轴、寻轨等。访问硬盘和访问内存之间的速度差别是以数量级来计算的，就像1天和1分钟的差别一样。要监测 IO 性能，有必要了解一下基本原理和 Linux 是如何处理硬盘和内存之间的 IO 的。 在理解磁盘IO之前，同样我们需要理解一些概念，例如： 文件系统 VFS 文件系统缓存 页缓存page cache 缓冲区高速缓存buffer cache 目录缓存 inode inode缓存 noop调用策略 分析工具 工具 描述 iostat 磁盘详细统计信息 iotop 按进程查看磁盘IO统计信息 pidstat 查看每个进程的磁盘IO使用情况 iostatiostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况 CPU属性 %user：CPU处在用户模式下的时间百分比。 %nice：CPU处在带NICE值的用户模式下的时间百分比。 %system：CPU处在系统模式下的时间百分比。 %iowait：CPU等待输入输出完成时间的百分比。 %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。 %idle：CPU空闲时间百分比。 备注： 如果%iowait的值过高，表示硬盘存在I/O瓶颈 如果%idle值高，表示CPU较空闲 如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。 如果%idle值持续低于10，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。 Device属性 tps：该设备每秒的传输次数 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read： 读取的总数据量； kB_wrtn：写入的总数量数据量 常用命令： iostat 2 3 每隔2秒刷新显示，且显示3次 iostat -m 以M为单位显示所有信息 查看设备使用率（%util）、响应时间（await） iostat -d -x -k 1 1 iotop在一般运维工作中经常会遇到这么一个场景，服务器的IO负载很高（iostat中的util），但是无法快速的定位到IO负载的来源进程和来源文件导致无法进行相应的策略来解决问题。 如果你想检查那个进程实际在做 I/O，那么运行 iotop 命令加上 -o 或者 --only 参数。 iotop –only pidstat显示各个进程的IO使用情况 pidstat -d 报告IO统计显示以下信息： PID：进程id kB_rd/s：每秒从磁盘读取的KB kB_wr/s：每秒写入磁盘KB kB_ccwr/s：任务取消的写入磁盘的KB。当任务截断脏的pagecache的时候会发生。 COMMAND:task的命令名 网络分析工具 ping 测试网络的连通性 netstat 检验本机各端口的网络连接情况 hostname 查看主机和域名 ping常用命令参数： -d 使用Socket的SO_DEBUG功能。 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应。 -n 只输出数值。 -q 不显示任何传送封包的信息，只显示最后的结果。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题。 -R 记录路由过程。 -v 详细显示指令的执行过程。 -c 数目：在发送指定数目的包后停止。 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次。 -I 网络界面：使用指定的网络界面送出数据包。 -l 前置载入：设置在送出要求信息之前，先行发出的数据包。 -p 范本样式：设置填满数据包的范本样式。 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节。 -t 存活数值：设置存活数值TTL的大小。 ping -b 192.168.120.1 –ping网关 ping -c 10 192.168.120.206 –ping指定次数 ping -c 10 -i 0.5 192.168.120.206 –时间间隔和次数限制的ping netstatnetstat命令是一个监控TCP/IP网络的非常有用的工具，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息。 netstat [选项] 1234567891011-a或--all：显示所有连线中的Socket； -a (all) 显示所有选项，默认不显示LISTEN相关。-t (tcp) 仅显示tcp相关选项。-u (udp) 仅显示udp相关选项。-n 拒绝显示别名，能显示数字的全部转化成数字。-l 仅列出有在 Listen (监听) 的服务状态。-p 显示建立相关链接的程序名-r 显示路由信息，路由表-e 显示扩展信息，例如uid等-s 按各个协议进行统计-c 每隔一个固定时间，执行该netstat命令。 常用命令： 列出所有端口情况 123netstat -a # 列出所有端口netstat -at # 列出所有TCP端口netstat -au # 列出所有UDP端口 列出所有处于监听状态的 Sockets 1234netstat -l # 只显示监听端口netstat -lt # 显示监听TCP端口netstat -lu # 显示监听UDP端口netstat -lx # 显示监听UNIX端口 显示每个协议的统计信息 123netstat -s # 显示所有端口的统计信息netstat -st # 显示所有TCP的统计信息netstat -su # 显示所有UDP的统计信息 显示 PID 和进程名称 1netstat -p 显示网络统计信息 1netstat -s 统计机器中网络连接各个状态个数 1netstat&#96; &#96;-an | &#96;&#96;awk&#96; &#96;&#39;&#x2F;^tcp&#x2F; &#123;++S[$NF]&#125; END &#123;for (a in S) print a,S[a]&#125; &#39; 补充netstat网络状态详解： 一个正常的TCP连接，都会有三个阶段:1、TCP三次握手;2、数据传送;3、TCP四次挥手 TCP的连接释放 1234567891011LISTEN：侦听来自远方的TCP端口的连接请求SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了）SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态估计被flood攻击了）ESTABLISHED：代表一个打开的连接FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认FIN-WAIT-2：从远程TCP等待连接中断请求CLOSE-WAIT：等待从本地用户发来的连接中断请求CLOSING：等待远程TCP对连接中断的确认LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击）TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认CLOSED：没有任何连接状态 本文参考的文章: https://rdc.hundsun.com/portal/article/731.html?ref=myread","categories":[{"name":"Linux","slug":"Linux","permalink":"https://lingxizz.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://lingxizz.github.io/tags/Linux/"}]},{"title":"操作系统面试","slug":"basis","date":"2020-06-29T16:00:00.000Z","updated":"2020-12-08T02:44:25.737Z","comments":true,"path":"2020/06/30/basis/","link":"","permalink":"https://lingxizz.github.io/2020/06/30/basis/","excerpt":"","text":"文章形式通过大部分比较喜欢的面试官和求职者之间的对话形式展开。另外，Guide 哥也只是在大学的时候学习过操作系统，不过基本都忘了，为了写这篇文章这段时间看了很多相关的书籍和博客。如果文中有任何需要补充和完善的地方，你都可以在评论区指出。如果觉得内容不错的话，不要忘记点个在看哦！ 我个人觉得学好操作系统还是非常有用的，具体可以看我昨天在星球分享的一段话： 这篇文章只是对一些操作系统比较重要概念的一个概览，深入学习的话，建议大家还是老老实实地去看书。另外， 这篇文章的很多内容参考了《现代操作系统》第三版这本书，非常感谢。 一 操作系统基础面试官顶着蓬松的假发向我走来，只见他一手拿着厚重的 Thinkpad ，一手提着他那淡黄的长裙。 1.1 什么是操作系统？👨‍💻面试官 ： 先来个简单问题吧！什么是操作系统？ 🙋 我 ：我通过以下四点向您介绍一下什么是操作系统吧！ 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机系统的内核与基石； 操作系统本质上是运行在计算机上的软件程序 ； 操作系统为用户提供一个与系统交互的操作界面 ； 操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应用程序，而内核就是能操作硬件的程序）。 关于内核多插一嘴：内核负责管理系统的进程、内存、设备驱动程序、文件和网络系统等等，决定着系统的性能和稳定性。是连接应用程序和硬件的桥梁。内核就是操作系统背后黑盒的核心。 1.2 系统调用👨‍💻面试官 ：什么是系统调用呢？ 能不能详细介绍一下。 🙋 我 ：介绍系统调用之前，我们先来了解一下用户态和系统态。 根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别： 用户态(user mode) : 用户态运行的进程或可以直接读取用户程序的数据。 系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。 说了用户态和系统态之后，那么什么是系统调用呢？ 我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！ 也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。 这些系统调用按功能大致可分为如下几类： 设备管理。完成设备的请求或释放，以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 二 进程和线程2.1 进程和线程的区别👨‍💻面试官: 好的！我明白了！那你再说一下： 进程和线程的区别。 🙋 我： 好的！ 下图是 Java 内存区域，我们从 JVM 的角度来说一下线程和进程之间的关系吧！ 如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下这篇文章：《可能是把 Java 内存区域讲的最清楚的一篇文章》 从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。 总结： 线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。 2.2 进程有哪几种状态?👨‍💻面试官 ： 那你再说说进程有哪几种状态? 🙋 我 ：我们一般把进程大致分为 5 种状态，这一点和线程很像！ 创建状态(new) ：进程正在被创建，尚未到就绪状态。 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。 订正：下图中 running 状态被 interrupt 向 ready 状态转换的箭头方向反了。 2.3 进程间的通信方式👨‍💻面试官 ：进程间的通信常见的的有哪几种方式呢? 🙋 我 ：大概有 7 种常见的进程间的通信方式。 下面这部分总结参考了:《进程间通信 IPC (InterProcess Communication)》 这篇文章，推荐阅读，总结的非常不错。 管道/匿名管道(Pipes) ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 有名管道(Names Pipes) : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。 信号(Signal) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列(Message Queuing) ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。 信号量(Semaphores) ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。 共享内存(Shared memory) ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。 套接字(Sockets) : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。 2.4 线程间的同步的方式👨‍💻面试官 ：那线程间的同步的方式有哪些呢? 🙋 我 ：线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式： 互斥量(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 信号量(Semphares) ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操 2.5 进程的调度算法👨‍💻面试官 ：你知道操作系统中进程的调度算法有哪些吗? 🙋 我 ：嗯嗯！这个我们大学的时候学过，是一个很重要的知识点！ 为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是： 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。 多级反馈队列调度算法 ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。 三 操作系统内存管理基础3.1 内存管理介绍👨‍💻 面试官: 操作系统的内存管理主要是做什么？ 🙋 我： 操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。 3.2 常见的几种内存管理机制👨‍💻 面试官: 操作系统的内存管理机制了解吗？内存管理有哪几种方式? 🙋 我： 这个在学习操作系统的时候有了解过。 简单分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 块式管理 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理 和 段式管理。 块式管理 ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 页式管理 ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理 ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。 👨‍💻面试官 ： 回答的还不错！不过漏掉了一个很重要的 段页式管理机制 。段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制 中段与段之间以及段的内部的都是离散的。 🙋 我 ：谢谢面试官！刚刚把这个给忘记了～ 3.3 快表和多级页表👨‍💻面试官 ： 页表管理机制中有两个很重要的概念：快表和多级页表，这两个东西分别解决了页表管理中很重要的两个问题。你给我简单介绍一下吧！ 🙋 我 ：在分页内存管理中，很重要的两点是： 虚拟地址到物理地址的转换要快。 解决虚拟地址空间大，页表也会很大的问题。 快表为了解决虚拟地址到物理地址的转换速度，操作系统在 页表方案 基础之上引入了 快表 来加速虚拟地址到物理地址的转换。我们可以把块表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。 使用快表之后的地址转换流程是这样的： 根据虚拟地址中的页号查快表； 如果该页在快表中，直接从快表中读取相应的物理地址； 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中； 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。 看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。 多级页表引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章 多级页表如何节约内存：https://www.polarxiong.com/archives/多级页表如何节约内存.html 总结为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是多级页表实际上都利用到了程序的局部性原理，局部性原理在后面的虚拟内存这部分会介绍到。 3.4 分页机制和分段机制的共同点和区别👨‍💻面试官 ： 分页机制和分段机制有哪些共同点和区别呢？ 🙋 我 ： 共同点 ： 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。 区别 ： 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。 3.5 逻辑(虚拟)地址和物理地址👨‍💻面试官 ：你刚刚还提到了逻辑地址和物理地址这两个概念，我不太清楚，你能为我解释一下不？ 🙋 我： em…好的嘛！我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。 3.6 CPU 寻址了解吗?为什么需要虚拟地址空间?👨‍💻面试官 ：CPU 寻址了解吗?为什么需要虚拟地址空间? 🙋 我 ：这部分我真不清楚！ 于是面试完之后我默默去查阅了相关文档！留下了没有技术的泪水。。。 这部分内容参考了 Microsoft 官网的介绍，地址：https://msdn.microsoft.com/zh-cn/library/windows/hardware/hh439648(v=vs.85).aspx 现代处理器使用的是一种称为 虚拟寻址(Virtual Addressing) 的寻址方式。使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 内存管理单元（Memory Management Unit, MMU） 的硬件。如下图所示： 为什么要有虚拟地址空间呢？ 先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，程序都是直接访问和操作的都是物理内存 。但是这样有什么问题呢？ 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。 总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。 通过虚拟地址访问内存有以下优势： 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。 四 虚拟内存4.1 什么是虚拟内存(Virtual Memory)?👨‍💻面试官 ：再问你一个常识性的问题！什么是虚拟内存(Virtual Memory)? 🙋 我 ：这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢？ 正是因为 虚拟内存 的存在，通过 虚拟内存 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。这样会更加有效地管理内存并减少出错。 虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间。推荐阅读：《虚拟内存的那点事儿》 维基百科中有几句话是这样介绍虚拟内存的。 虚拟内存 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。From:https://zh.wikipedia.org/wiki/虚拟内存 4.2 局部性原理👨‍💻面试官 ：要想更好地理解虚拟内存技术，必须要知道计算机中著名的局部性原理。另外，局部性原理既适用于程序结构，也适用于数据结构，是非常重要的一个概念。 🙋 我 ：局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。 以下内容摘自《计算机操作系统教程》 第 4 章存储器管理。 早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。 局部性原理表现在以下两个方面： 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。 4.3 虚拟存储器👨‍💻面试官 ：都说了虚拟内存了。你再讲讲虚拟存储器把！ 🙋 我 ： 这部分内容来自：王道考研操作系统知识点整理。 基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——虚拟存储器。 实际上，我觉得虚拟内存同样是一种时间换空间的策略，你用 CPU 的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。不得不感叹，程序世界几乎不是时间换空间就是空间换时间。 4.4 虚拟内存的技术实现👨‍💻面试官 ：虚拟内存技术的实现呢？ 🙋 我 ：虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式： 请求分页存储管理 ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 请求分段存储管理 ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。 请求段页式存储管理 这里多说一下？很多人容易搞混请求分页与分页存储管理，两者有何不同呢？ 请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。 它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。 不管是上面那种实现方式，我们一般都需要： 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了； 缺页中断：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序； 虚拟地址空间 ：逻辑地址到物理地址的变换。 4.5 页面置换算法👨‍💻面试官 ：虚拟内存管理很重要的一个概念就是页面置换算法。那你说一下 页面置换算法的作用?常见的页面置换算法有哪些? 🙋 我 ： 这个题目经常作为笔试题出现，网上已经给出了很不错的回答，我这里只是总结整理了一下。 地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。 缺页中断 就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。 当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。 OPT 页面置换算法（最佳页面置换算法） ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。 FIFO（First In First Out） 页面置换算法（先进先出页面置换算法） : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。 LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法） ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。 LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法） : 该置换算法选择在之前时期使用最少的页面作为淘汰页。 Reference 《计算机操作系统—汤小丹》第四版 《深入理解计算机系统》 https://zh.wikipedia.org/wiki/输入输出内存管理单元 https://baike.baidu.com/item/快表/19781679 https://www.jianshu.com/p/1d47ed0b46d5 https://www.studytonight.com/operating-system https://www.geeksforgeeks.org/interprocess-communication-methods/ https://juejin.im/post/59f8691b51882534af254317 王道考研操作系统知识点整理： https://wizardforcel.gitbooks.io/wangdaokaoyan-os/content/13.html","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://lingxizz.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://lingxizz.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux基础命令","slug":"linux","date":"2020-06-29T16:00:00.000Z","updated":"2020-12-08T02:41:28.111Z","comments":true,"path":"2020/06/30/linux/","link":"","permalink":"https://lingxizz.github.io/2020/06/30/linux/","excerpt":"","text":"一 从认识操作系统开始 1.1 操作系统简介 1.2 操作系统简单分类 二 初探Linux 2.1 Linux简介 2.2 Linux诞生简介 2.3 Linux的分类 三 Linux文件系统概览 3.1 Linux文件系统简介 3.2 文件类型与目录结构 四 Linux基本命令 4.1 目录切换命令 4.2 目录的操作命令（增删改查） 4.3 文件的操作命令（增删改查） 4.4 压缩文件的操作命令 4.5 Linux的权限命令 4.6 Linux 用户管理 4.7 Linux系统用户组的管理 4.8 其他常用命令 推荐一个Github开源的Linux学习指南(Java工程师向)：https://github.com/judasn/Linux-Tutorial 学习Linux之前，我们先来简单的认识一下操作系统。 一 从认识操作系统开始1.1 操作系统简介我通过以下四点介绍什么是操作系统： 操作系统（Operation System，简称OS）是管理计算机硬件与软件资源的程序，是计算机系统的内核与基石； 操作系统本质上是运行在计算机上的软件程序 ； 为用户提供一个与系统交互的操作界面 ； 操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应用程序，而内核就是能操作硬件的程序）。 1.2 操作系统简单分类 Windows: 目前最流行的个人桌面操作系统 ，不做多的介绍，大家都清楚。 Unix： 最早的多用户、多任务操作系统 .按照操作系统的分类，属于分时操作系统。Unix 大多被用在服务器、工作站，现在也有用在个人计算机上。它在创建互联网、计算机网络或客户端/服务器模型方面发挥着非常重要的作用。 Linux: Linux是一套免费使用和自由传播的类Unix操作系统.Linux存在着许多不同的Linux版本，但它们都使用了 Linux内核 。Linux可安装在各种计算机硬件设备中，比如手机、平板电脑、路由器、视频游戏控制台、台式计算机、大型机和超级计算机。严格来讲，Linux这个词本身只表示Linux内核，但实际上人们已经习惯了用Linux来形容整个基于Linux内核，并且使用GNU 工程各种工具和数据库的操作系统。 1.3 操作系统的内核图源:简书 (如有侵权,请联系俺,俺会立刻删除) 操作系统的内核是操作系统的核心部分。它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 我们常说的Linux，其实是指基于Linux内核开发的操作系统。常见的Linux系统发行版有:Debian,RedHat,Ubuntu,Suse,Centeos等等。 操作系统的用户态与内核态unix与linux的体系架构：分为用户态与内核态。用户态与内核态是操作系统对执行权限进行分级后的不同的运行模式。 为什么要有用户态与内核态?在cpu的所有指令中，有些指令是非常危险的，如果使用不当，将会造成系统崩溃等后果。为了避免这种情况发生，cpu将指令划分为特权级(内核态)指令和非特权级(用户态)指令。 对于那些危险的指令只允许内核及其相关模块调用，对于那些不会造成危险的指令，就允许用户应用程序调用。 内核态(核心态,特权态): 内核态是操作系统内核运行的模式。内核态控制计算机的硬件资源，如硬件设备，文件系统等等，并为上层应用程序提供执行环境。 用户态: 用户态是用户应用程序运行的状态。应用程序必须依托于内核态运行,因此用户态的态的操作权限比内核态是要低的，如磁盘，文件等，访问操作都是受限的。 系统调用: 系统调用是操作系统为应用程序提供能够访问到内核态的资源的接口。 用户态切换到内核态的几种方式 系统调用: 系统调用是用户态主动要求切换到内核态的一种方式，用户应用程序通过操作系统调用内核为上层应用程序开放的接口来执行程序。 异常: 当cpu在执行用户态的应用程序时，发生了某些不可知的异常。于是当前用户态的应用进程切换到处理此异常的内核的程序中去。 硬件设备的中断: 当硬件设备完成用户请求后，会向cpu发出相应的中断信号，这时cpu会暂停执行下一条即将要执行的指令，转而去执行与中断信号对应的应用程序，如果先前执行的指令是用户态下程序的指令，那么这个转换过程也是用户态到内核台的转换。 物理内存RAM(Random Access Memory 随机存储器)物理内存是计算机的实际内存大小，它直接与CPU交换数据，也被称为主存。 虚拟内存(Virtual Memory)虚拟内存是操作系统为了更高效率使用物理内存的一种概念，它是对物理内存的抽象。windows上的虚拟内存和Linux上的swap交换空间都是虚拟内存的一种实现技术。 Swap交换空间简单理解: 当某个应用程序所需的内存空间不够了，那么系统会判断当前物理内存是否还有足够的空闲可以分配给应用程序。如果有，则应用程序直接进入内存运行；如果没有，系统就根据某种算法(如:LRU)挂起一个进程，将挂起的进程交换到虚拟内存Swap中等待，并将应用程序调入内存执行。虚拟内存是被虚拟出来的，可以使用硬盘(不仅仅是硬盘)来作为虚拟内存。 这就是为什么当我们运行一个所需内存比我们计算机内存还大的程序时，仍然可以正常运行，并感受不到内存的限制的原因。 二 初探Linux2.1 Linux简介我们上面已经介绍到了Linux，我们这里只强调三点。 类Unix系统： Linux是一种自由、开放源码的类似Unix的操作系统 Linux内核： 严格来说，Linux这个词本身只表示Linux内核 Linux之父： 一个编程领域的传奇式人物。他是Linux内核的最早作者，随后发起了这个开源项目，担任Linux内核的首要架构师与项目协调者，是当今世界最著名的电脑程序员、黑客之一。他还发起了Git这个开源项目，并为主要的开发者。 2.2 Linux诞生简介 1991年，芬兰的业余计算机爱好者Linus Torvalds编写了一款类似Minix的系统（基于微内核架构的类Unix操作系统）被ftp管理员命名为Linux 加入到自由软件基金的GNU计划中; Linux以一只可爱的企鹅作为标志，象征着敢作敢为、热爱生活。 2.3 Linux的分类Linux根据原生程度，分为两种： 内核版本： Linux不是一个操作系统，严格来讲，Linux只是一个操作系统中的内核。内核是什么？内核建立了计算机软件与硬件之间通讯的平台，内核提供系统服务，比如文件管理、虚拟内存、设备I/O等； 发行版本： 一些组织或公司在内核版基础上进行二次开发而重新发行的版本。Linux发行版本有很多种（ubuntu和CentOS用的都很多，初学建议选择CentOS），如下图所示： 三 Linux文件系统概览3.1 Linux文件系统简介在Linux操作系统中，所有被操作系统管理的资源，例如网络接口卡、磁盘驱动器、打印机、输入输出设备、普通文件或是目录都被看作是一个文件。 也就是说在LINUX系统中有一个重要的概念：一切都是文件。其实这是UNIX哲学的一个体现，而Linux是重写UNIX而来，所以这个概念也就传承了下来。在UNIX系统中，把一切资源都看作是文件，包括硬件设备。UNIX系统把每个硬件都看成是一个文件，通常称为设备文件，这样用户就可以用读写文件的方式实现对硬件的访问。 3.2 Inodeinode是linux/unix文件系统和硬盘存储的基础，如果理解了inode，将会对我们学习如何将复杂的概念抽象成简单概念有重大帮助。 Inode是什么?有什么作用?文件存储在硬盘上，硬盘的最小存储单位是扇区(Sector),每个扇区存储512字节(0.5kb)。操作系统读取硬盘的数据时，不会一个扇区一个扇区的读取，这样做效率较低，而是一次读取多个扇区，即一次读取一个块(block)。块由多个扇区组成，是文件读取的最小单位，块的最常见的大小是4kb，约为8个连续的扇区组成。文件数据存储在块中，但还需要一个空间来存储文件的元信息metadata，如文件拥有者，创建时间，权限，大小等。这种存储文件元信息的区域就叫inode，译为索引节点。 每个文件都有一个inode，存储文件的元信息。使用 stat 命令可以查看文件的inode信息。每个inode都有一个号码，Linux/Unix操作系统不使用文件名来区分文件，而是使用inode号码区分不同的文件。 inode也需要消耗硬盘空间，所以在格式化硬盘的时候，操作系统会将硬盘分为2个区域，一个区域存放文件数据，另一个区域存放inode所包含的信息，存放inode的区域被称为inode table。 文件的inode信息: 3.3 文件类型与目录结构**Linux支持很多文件类型，其中非常重要的文件类型有:普通文件，目录文件，链接文件，设备文件，管道文件，Socket套接字文件等。 普通文件: 普通文件是指txt,html,pdf等等的这样应用层面的文件类型，用户可以根据访问权限对普通文件进行访问，修改和删除。 目录文件: 目录也是一种文件，打开目录实际上是打开目录文件。目录文件包含了它目录下的所有文件名以及指向这些文件的指针。 链接文件: 链接文件分为符号链接(软链接)文件和硬链接文件 硬链接(Hard Link):硬链接的文件拥有相同的inode，因为操作系统是靠inode来区分文件的，2个inode相同的文件，就代表它们是一个文件。删除一个文件并不会对其他拥有相同inode的文件产生影响，只有当inode相同的所有文件被删除了，这个文件才会被删除。换言之，你建立一个文件的硬链接，这个文件和硬链接它们的inode是相同的,无论你删除的是硬链接还是源文件，都不会对彼此造成影响,除非你把硬链接和源文件都删除，这个文件才被删除。 符号链接(软链接)(Symbolic Link): 符号链接类似于Windows上的快捷方式，它保存了源文件的路径。当符号链接被删除时，并不会影响源文件。但是当源文件被删除时，符号链接就找不到源文件了。 软链接和硬链接: 设备文件设备文件分为块设备文件和字符设备文件,设备文件一般存于/dev目录下。 字符设备文件: 字符设备是依照先后顺序被存取数据的设备，通常不支持随机存取，此类设备可以按字节/字符来读取数据， 如键盘，串口等等。 块设备文件: 块设备是可以被随机存取数据的设备，应用程序可以访问块设备上任何一块位置。块设备以块的方式读取数据，在windows下也称为簇，块设备不支持字符的方式寻址。如硬盘，软盘，光碟等等。 字符设备与块设备最根本的区别就是它们是否可以被随机访问。如键盘，当我们在键盘上敲下一个单词: “word”的时候，那么系统肯定是需要按照顺序来进行读取word的字节流(字符流)的，随机访问在此时是没有意义的。 管道文件: 管道文件一般用于进程间通信，使用mkfifo命令可以创建一个管道文件。 Socket套接字文件: 套接字文件被用于网络进程之间的通信，既可以使2台不同的机器进行通信，也可以用于本机的Socket网络程序。 Linux目录树所有可操作的计算机资源都存在于目录树这个结构中，对计算资源的访问，可以看做是对这棵目录树的访问。 Linux的目录结构如下： Linux文件系统的结构层次鲜明，就像一棵倒立的树，最顶层是其根目录： 常见目录说明： /bin： 存放二进制可执行文件(ls、cat、mkdir等)，常用命令一般都在这里； /etc： 存放系统管理和配置文件； /home： 存放所有用户文件的根目录，是用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示； /usr ： 用于存放系统应用程序； /opt： 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把tomcat等都安装到这里； /proc： 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息； /root： 超级用户（系统管理员）的主目录（特权阶级^o^）； /sbin: 存放二进制可执行文件，只有root才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如ifconfig等； /dev： 用于存放设备文件； /mnt： 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统； /boot： 存放用于系统引导时使用的各种文件； /lib ： 存放着和系统运行相关的库文件 ； /tmp： 用于存放各种临时文件，是公用的临时文件存储点； /var： 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等； /lost+found： 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里。 四 Linux基本命令下面只是给出了一些比较常用的命令。推荐一个Linux命令快查网站，非常不错，大家如果遗忘某些命令或者对某些命令不理解都可以在这里得到解决。 Linux命令大全：http://man.linuxde.net/ 4.1 目录切换命令 cd usr： 切换到该目录下usr目录 cd ..（或cd../）： 切换到上一层目录 cd /： 切换到系统根目录 cd ~： 切换到用户主目录 cd -： 切换到上一个操作所在目录 4.2 目录的操作命令(增删改查) mkdir 目录名称： 增加目录 ls或者ll（ll是ls -l的别名，ll命令可以看到该目录下的所有目录和文件的详细信息）：查看目录信息 find 目录 参数： 寻找目录（查） 示例： 列出当前目录及子目录下所有文件和文件夹: find . 在/home目录下查找以.txt结尾的文件名:find /home -name &quot;*.txt&quot; 同上，但忽略大小写: find /home -iname &quot;*.txt&quot; 当前目录及子目录下查找所有以.txt和.pdf结尾的文件:find . \\( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \\)或find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; mv 目录名称 新目录名称： 修改目录的名称（改） 注意：mv的语法不仅可以对目录进行重命名而且也可以对各种文件，压缩包等进行 重命名的操作。mv命令用来对文件或目录重新命名，或者将文件从一个目录移到另一个目录中。后面会介绍到mv命令的另一个用法。 mv 目录名称 目录的新位置： 移动目录的位置—剪切（改） 注意：mv语法不仅可以对目录进行剪切操作，对文件和压缩包等都可执行剪切操作。另外mv与cp的结果不同，mv好像文件“搬家”，文件个数并未增加。而cp对文件进行复制，文件个数增加了。 cp -r 目录名称 目录拷贝的目标位置： 拷贝目录（改），-r代表递归拷贝 注意：cp命令不仅可以拷贝目录还可以拷贝文件，压缩包等，拷贝文件和压缩包时不 用写-r递归 rm [-rf] 目录: 删除目录（删） 注意：rm不仅可以删除目录，也可以删除其他文件或压缩包，为了增强大家的记忆， 无论删除任何目录或文件，都直接使用rm -rf 目录/文件/压缩包 4.3 文件的操作命令(增删改查) touch 文件名称: 文件的创建（增） cat/more/less/tail 文件名称 文件的查看（查） cat： 查看显示文件内容 more： 可以显示百分比，回车可以向下一行， 空格可以向下一页，q可以退出查看 less： 可以使用键盘上的PgUp和PgDn向上 和向下翻页，q结束查看 tail-10 ： 查看文件的后10行，Ctrl+C结束 注意：命令 tail -f 文件 可以对某个文件进行动态监控，例如tomcat的日志文件， 会随着程序的运行，日志会变化，可以使用tail -f catalina-2016-11-11.log 监控 文 件的变化 vim 文件： 修改文件的内容（改） vim编辑器是Linux中的强大组件，是vi编辑器的加强版，vim编辑器的命令和快捷方式有很多，但此处不一一阐述，大家也无需研究的很透彻，使用vim编辑修改文件的方式基本会使用就可以了。 在实际开发中，使用vim编辑器主要作用就是修改配置文件，下面是一般步骤： vim 文件——&gt;进入文件—–&gt;命令模式——&gt;按i进入编辑模式—–&gt;编辑文件 ——-&gt;按Esc进入底行模式—–&gt;输入：wq/q! （输入wq代表写入内容并退出，即保存；输入q!代表强制退出不保存。） rm -rf 文件： 删除文件（删） 同目录删除：熟记 rm -rf 文件 即可 4.4 压缩文件的操作命令1）打包并压缩文件： Linux中的打包文件一般是以.tar结尾的，压缩的命令一般是以.gz结尾的。 而一般情况下打包和压缩是一起进行的，打包并压缩后的文件的后缀名一般.tar.gz。命令：tar -zcvf 打包压缩后的文件名 要打包压缩的文件其中： z：调用gzip压缩命令进行压缩 c：打包文件 v：显示运行过程 f：指定文件名 比如：假如test目录下有三个文件分别是：aaa.txt bbb.txt ccc.txt，如果我们要打包test目录并指定压缩后的压缩包名称为test.tar.gz可以使用命令：tar -zcvf test.tar.gz aaa.txt bbb.txt ccc.txt或：tar -zcvf test.tar.gz /test/ 2）解压压缩包： 命令：tar [-xvf] 压缩文件 其中：x：代表解压 示例： 1 将/test下的test.tar.gz解压到当前目录下可以使用命令：tar -xvf test.tar.gz 2 将/test下的test.tar.gz解压到根目录/usr下:tar -xvf test.tar.gz -C /usr（- C代表指定解压的位置） 4.5 Linux的权限命令 操作系统中每个文件都拥有特定的权限、所属用户和所属组。权限是操作系统用来限制资源访问的机制，在Linux中权限一般分为读(readable)、写(writable)和执行(excutable)，分为三组。分别对应文件的属主(owner)，属组(group)和其他用户(other)，通过这样的机制来限制哪些用户、哪些组可以对特定的文件进行什么样的操作。通过 ls -l 命令我们可以 查看某个目录下的文件或目录的权限 示例：在随意某个目录下ls -l 第一列的内容的信息解释如下： 下面将详细讲解文件的类型、Linux中权限以及文件有所有者、所在组、其它组具体是什么？ 文件的类型： d： 代表目录 -： 代表文件 l： 代表软链接（可以认为是window中的快捷方式） Linux中权限分为以下几种： r：代表权限是可读，r也可以用数字4表示 w：代表权限是可写，w也可以用数字2表示 x：代表权限是可执行，x也可以用数字1表示 文件和目录权限的区别： 对文件和目录而言，读写执行表示不同的意义。 对于文件： 权限名称 可执行操作 r 可以使用cat查看文件的内容 w 可以修改文件的内容 x 可以将其运行为二进制文件 对于目录： 权限名称 可执行操作 r 可以查看目录下列表 w 可以创建和删除目录下文件 x 可以使用cd进入目录 需要注意的是超级用户可以无视普通用户的权限，即使文件目录权限是000，依旧可以访问。在linux中的每个用户必须属于一个组，不能独立于组外。在linux中每个文件有所有者、所在组、其它组的概念。 所有者 一般为文件的创建者，谁创建了该文件，就天然的成为该文件的所有者，用ls ‐ahl命令可以看到文件的所有者 也可以使用chown 用户名 文件名来修改文件的所有者 。 文件所在组 当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组 用ls ‐ahl命令可以看到文件的所有组 也可以使用chgrp 组名 文件名来修改文件所在的组。 其它组 除开文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组 我们再来看看如何修改文件/目录的权限。 修改文件/目录的权限的命令：chmod 示例：修改/test下的aaa.txt的权限为属主有全部权限，属主所在的组有读写权限，其他用户只有读的权限 chmod u=rwx,g=rw,o=r aaa.txt chmod -R u=rwx,g=rwx,o=rwx ./log // 递归给log目录下的所有文件授权 上述示例还可以使用数字表示： chmod 764 aaa.txt 补充一个比较常用的东西: 假如我们装了一个zookeeper，我们每次开机到要求其自动启动该怎么办？ 新建一个脚本zookeeper 为新建的脚本zookeeper添加可执行权限，命令是:chmod +x zookeeper 把zookeeper这个脚本添加到开机启动项里面，命令是：chkconfig --add zookeeper 如果想看看是否添加成功，命令是：chkconfig --list 4.6 Linux 用户管理Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 Linux用户管理相关命令: useradd 选项 用户名:添加用户账号 userdel 选项 用户名:删除用户帐号 usermod 选项 用户名:修改帐号 passwd 用户名:更改或创建用户的密码 passwd -S 用户名 :显示用户账号密码信息 passwd -d 用户名: 清除用户密码 useradd命令用于Linux中创建的新的系统用户。useradd可用来建立用户帐号。帐号建好之后，再用passwd设定帐号的密码．而可用userdel删除帐号。使用useradd指令所建立的帐号，实际上是保存在/etc/passwd文本文件中。 passwd命令用于设置用户的认证信息，包括用户密码、密码过期时间等。系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 4.7 Linux系统用户组的管理每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。 Linux系统用户组的管理相关命令: groupadd 选项 用户组 :增加一个新的用户组 groupdel 用户组:要删除一个已有的用户组 groupmod 选项 用户组 : 修改用户组的属性 4.8 其他常用命令 pwd： 显示当前所在位置 sudo + 其他命令：以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行。 grep 要搜索的字符串 要搜索的文件 --color： 搜索命令，–color代表高亮显示 ps -ef/ps -aux： 这两个命令都是查看当前系统正在运行进程，两者的区别是展示格式不同。如果想要查看特定的进程可以使用这样的格式：ps aux|grep redis （查看包括redis字符串的进程），也可使用 pgrep redis -a。 注意：如果直接用ps（（Process Status））命令，会显示所有进程的状态，通常结合grep命令查看某进程的状态。 kill -9 进程的pid： 杀死进程（-9 表示强制终止。） 先用ps查找进程，然后用kill杀掉 网络通信命令： 查看当前系统的网卡信息：ifconfig 查看与某台机器的连接情况：ping 查看当前系统的端口使用：netstat -an net-tools 和 iproute2 ： net-tools起源于BSD的TCP/IP工具箱，后来成为老版本Linux内核中配置网络功能的工具。但自2001年起，Linux社区已经对其停止维护。同时，一些Linux发行版比如Arch Linux和CentOS/RHEL 7则已经完全抛弃了net-tools，只支持iproute2。linux ip命令类似于ifconfig，但功能更强大，旨在替代它。更多详情请阅读如何在Linux中使用IP命令和示例 shutdown： shutdown -h now： 指定现在立即关机；shutdown +5 &quot;System will shutdown after 5 minutes&quot;：指定5分钟后关机，同时送出警告信息给登入用户。 reboot： reboot： 重开机。reboot -w： 做个重开机的模拟（只有纪录并不会真的重开机）。 公众号如果大家想要实时关注我更新的文章以及分享的干货的话，可以关注我的公众号。 《Java面试突击》: 由本文档衍生的专为面试而生的《Java面试突击》V2.0 PDF 版本公众号后台回复 “Java面试突击” 即可免费领取！ Java工程师必备学习资源: 一些Java工程师常用学习资源公众号后台回复关键字 “1” 即可免费无套路获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://lingxizz.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://lingxizz.github.io/tags/Linux/"}]},{"title":"计算机网络","slug":"计算机网络","date":"2020-06-29T16:00:00.000Z","updated":"2020-12-08T09:53:26.290Z","comments":true,"path":"2020/06/30/计算机网络/","link":"","permalink":"https://lingxizz.github.io/2020/06/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"一 OSI与TCP/IP各层的结构与功能,都有哪些协议?学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。 结合互联网的情况，自上而下地，非常简要的介绍一下各层的作用。 1.1 应用层应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统DNS，支持万维网应用的 HTTP协议，支持电子邮件的 SMTP协议等等。我们把应用层交互的数据单元称为报文。 域名系统 域名系统(Domain Name System缩写 DNS，Domain Name被译为域名)是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。（百度百科）例如：一个公司的 Web 网站可看作是它在网上的门户，而域名就相当于其门牌地址，通常域名都使用该公司的名称或简称。例如上面提到的微软公司的域名，类似的还有：IBM 公司的域名是 www.ibm.com、Oracle 公司的域名是 www.oracle.com、Cisco公司的域名是 www.cisco.com 等。 HTTP协议 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。（百度百科） 1.2 运输层运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。 运输层主要使用以下两种协议: 传输控制协议 TCP（Transmission Control Protocol）–提供面向连接的，可靠的数据传输服务。 用户数据协议 UDP（User Datagram Protocol）–提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。 TCP 与 UDP 的对比见问题三。 1.3 网络层在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。 这里要注意：不要把运输层的“用户数据报 UDP ”和网络层的“ IP 数据报”弄混。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。 这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称. 互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Protocol）和许多路由选择协议，因此互联网的网络层也叫做网际层或IP层。 1.4 数据链路层数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。 在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。 1.5 物理层在物理层上所传送的数据单位是比特。 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 在互联网使用的各种协中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的TCP/IP并不一定单指TCP和IP这两个具体的协议，而往往表示互联网所使用的整个TCP/IP协议族。 1.6 总结一下上面我们对计算机网络的五层体系结构有了初步的了解，下面附送一张七层体系结构图总结一下（图片来源于网络）。 二 TCP 三次握手和四次挥手(面试常客)为了准确无误地把数据送达目标处，TCP协议采用了三次握手策略。 2.1 TCP 三次握手漫画图解如下图所示，下面的两个机器人通过3次握手确定了对方能正确接收和发送消息(图片来源：《图解HTTP》)。 简单示意图： 客户端–发送带有 SYN 标志的数据包–一次握手–服务端 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端 2.2 为什么要三次握手三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 所以三次握手就能确认双发收发功能都正常，缺一不可。 2.3 第2次握手传回了ACK，为什么还要传回SYN？接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信。” SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。 2.5 为什么要四次挥手 断开一个 TCP 连接则需要“四次挥手”： 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号 服务器-关闭与客户端的连接，发送一个FIN给客户端 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。 举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。 上面讲的比较概括，推荐一篇讲的比较细致的文章：https://blog.csdn.net/qzcsu/article/details/72861891 三 TCP,UDP 协议的区别 UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等 TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。 四 TCP 协议如何保证可靠传输 应用数据被分割成 TCP 认为最适合发送的数据块。 TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 TCP 的接收端会丢弃重复的数据。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 4.1 ARQ协议自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。 停止等待ARQ协议 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组； 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认； 优点： 简单 缺点： 信道利用率低，等待时间长 1) 无差错情况: 发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。 2) 出现差错情况（超时重传）: 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 自动重传请求 ARQ 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续 ARQ 协议 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。 3) 确认丢失和确认迟到 确认丢失 ：确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。 确认迟到 ：确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。 连续ARQ协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。 4.2 滑动窗口和流量控制TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 4.3 拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。 拥塞避免： 拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1. 快重传与快恢复：在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 五 在浏览器中输入url地址 -&gt;&gt; 显示主页的过程(面试常客)百度好像最喜欢问这个问题。 打开一个网页，整个过程会使用哪些协议 图解（图片来源：《图解HTTP》）： 总体来说分为以下几个过程: DNS解析 TCP连接 发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析渲染页面 连接结束 具体可以参考下面这篇文章： https://segmentfault.com/a/1190000006879700 六 状态码 七 各种协议与HTTP协议之间的关系一般面试官会通过这样的问题来考察你对计算机网络知识体系的理解。 图片来源：《图解HTTP》 八 HTTP长连接,短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 —— 《HTTP长连接、短连接究竟是什么？》 九 HTTP是不保存状态的协议,如何保存用户状态?HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。 在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。 Cookie 被禁用怎么办? 最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。 十 Cookie的作用是什么?和Session有什么区别？Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。 Cookie 一般用来保存用户信息 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。 Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。 十一 HTTP 1.0和HTTP 1.1的主要区别是什么? 这部分回答引用这篇文章 https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A? 的一些内容。 HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在： 长连接 : 在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。 错误状态响应码 :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 缓存处理 :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用 :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 十二 URI和URL的区别是什么? URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。 URL(Uniform Resource Location) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。 十三 HTTP 和 HTTPS 的区别？ 端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。 安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等； 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。 建议非常推荐大家看一下 《图解HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。 参考 https://blog.csdn.net/qq_16209077/article/details/52718250 https://blog.csdn.net/zixiaomuwu/article/details/60965466 https://blog.csdn.net/turn__back/article/details/73743641 https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://lingxizz.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://lingxizz.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"volatile关键字","slug":"061605","date":"2020-06-15T16:00:00.000Z","updated":"2020-12-08T02:44:42.089Z","comments":true,"path":"2020/06/16/061605/","link":"","permalink":"https://lingxizz.github.io/2020/06/16/061605/","excerpt":"","text":"volatile的用途1.线程可见性12345678910111213141516171819package com.mashibing.testvolatile;public class T01_ThreadVisibility &#123; private static volatile boolean flag = true; public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt; &#123; while (flag) &#123; //do sth &#125; System.out.println(&quot;end&quot;); &#125;, &quot;server&quot;).start(); Thread.sleep(1000); flag = false; &#125;&#125; 2.防止指令重排序问题：DCL单例需不需要加volatile？CPU的基础知识 缓存行对齐缓存行64个字节是CPU同步的基本单位，缓存行隔离会比伪共享效率要高Disruptor 12345678910111213141516171819202122232425262728293031323334353637383940package com.mashibing.juc.c_028_FalseSharing;public class T02_CacheLinePadding &#123; private static class Padding &#123; public volatile long p1, p2, p3, p4, p5, p6, p7; // &#125; private static class T extends Padding &#123; public volatile long x = 0L; &#125; public static T[] arr = new T[2]; static &#123; arr[0] = new T(); arr[1] = new T(); &#125; public static void main(String[] args) throws Exception &#123; Thread t1 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_0000L; i++) &#123; arr[0].x = i; &#125; &#125;); Thread t2 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_0000L; i++) &#123; arr[1].x = i; &#125; &#125;); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println((System.nanoTime() - start)/100_0000); &#125;&#125; MESI 伪共享 合并写CPU内部的4个字节的Buffer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.mashibing.juc.c_029_WriteCombining;public final class WriteCombining &#123; private static final int ITERATIONS = Integer.MAX_VALUE; private static final int ITEMS = 1 &lt;&lt; 24; private static final int MASK = ITEMS - 1; private static final byte[] arrayA = new byte[ITEMS]; private static final byte[] arrayB = new byte[ITEMS]; private static final byte[] arrayC = new byte[ITEMS]; private static final byte[] arrayD = new byte[ITEMS]; private static final byte[] arrayE = new byte[ITEMS]; private static final byte[] arrayF = new byte[ITEMS]; public static void main(final String[] args) &#123; for (int i = 1; i &lt;= 3; i++) &#123; System.out.println(i + &quot; SingleLoop duration (ns) = &quot; + runCaseOne()); System.out.println(i + &quot; SplitLoop duration (ns) = &quot; + runCaseTwo()); &#125; &#125; public static long runCaseOne() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125; public static long runCaseTwo() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; &#125; i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125;&#125; 指令重排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.mashibing.jvm.c3_jmm;public class T04_Disorder &#123; private static int x = 0, y = 0; private static int a = 0, b =0; public static void main(String[] args) throws InterruptedException &#123; int i = 0; for(;;) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(new Runnable() &#123; public void run() &#123; //由于线程one先启动，下面这句话让它等一等线程two. 读着可根据自己电脑的实际性能适当调整等待时间. //shortWait(100000); a = 1; x = b; &#125; &#125;); Thread other = new Thread(new Runnable() &#123; public void run() &#123; b = 1; y = a; &#125; &#125;); one.start();other.start(); one.join();other.join(); String result = &quot;第&quot; + i + &quot;次 (&quot; + x + &quot;,&quot; + y + &quot;）&quot;; if(x == 0 &amp;&amp; y == 0) &#123; System.err.println(result); break; &#125; else &#123; //System.out.println(result); &#125; &#125; &#125; public static void shortWait(long interval)&#123; long start = System.nanoTime(); long end; do&#123; end = System.nanoTime(); &#125;while(start + interval &gt;= end); &#125;&#125; volatile如何解决指令重排序1: volatile i 2: ACC_VOLATILE 3: JVM的内存屏障 4：hotspot实现 bytecodeinterpreter.cpp 12345int field_offset = cache-&gt;f2_as_index(); if (cache-&gt;is_volatile()) &#123; if (support_IRIW_for_not_multiple_copy_atomic_cpu) &#123; OrderAccess::fence(); &#125; orderaccess_linux_x86.inline.hpp 12345678910inline void OrderAccess::fence() &#123; if (os::is_MP()) &#123; // always use locked addl since mfence is sometimes expensive#ifdef AMD64 __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);#else __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);#endif &#125;&#125;","categories":[{"name":"多线程","slug":"多线程","permalink":"https://lingxizz.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"https://lingxizz.github.io/tags/volatile/"}]},{"title":"synchronized关键字","slug":"061603","date":"2020-06-15T16:00:00.000Z","updated":"2020-12-08T02:44:54.202Z","comments":true,"path":"2020/06/16/061603/","link":"","permalink":"https://lingxizz.github.io/2020/06/16/061603/","excerpt":"","text":"用户态与内核态JDK早期，synchronized 叫做重量级锁， 因为申请锁资源必须通过kernel, 系统调用 123456789101112131415161718192021;hello.asm;write(int fd, const void *buffer, size_t nbytes)section data msg db &quot;Hello&quot;, 0xA len equ $ - msgsection .textglobal _start_start: mov edx, len mov ecx, msg mov ebx, 1 ;文件描述符1 std_out mov eax, 4 ;write函数系统调用号 4 int 0x80 mov ebx, 0 mov eax, 1 ;exit函数系统调用号 int 0x80 CASCompare And Swap (Compare And Exchange) / 自旋 / 自旋锁 / 无锁 （无重量锁） 因为经常配合循环操作，直到完成为止，所以泛指一类操作 cas(v, a, b) ，变量v，期待值a, 修改值b ABA问题，你的女朋友在离开你的这段儿时间经历了别的人，自旋就是你空转等待，一直等到她接纳你为止 解决办法（版本号 AtomicStampedReference），基础类型简单值不需要版本号 UnsafeAtomicInteger: 123456789101112public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125; &#125;public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; Unsafe: 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 运用： 12345678910111213141516171819202122232425262728package com.mashibing.jol;import sun.misc.Unsafe;import java.lang.reflect.Field;public class T02_TestUnsafe &#123; int i = 0; private static T02_TestUnsafe t = new T02_TestUnsafe(); public static void main(String[] args) throws Exception &#123; //Unsafe unsafe = Unsafe.getUnsafe(); Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); Field f = T02_TestUnsafe.class.getDeclaredField(&quot;i&quot;); long offset = unsafe.objectFieldOffset(f); System.out.println(offset); boolean success = unsafe.compareAndSwapInt(t, offset, 0, 1); System.out.println(success); System.out.println(t.i); //unsafe.compareAndSwapInt() &#125;&#125; jdk8u: unsafe.cpp: cmpxchg = compare and exchange 123456UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END jdk8u: atomic_linux_x86.inline.hpp 93行 is_MP = Multi Processor 12345678inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; int mp = os::is_MP(); __asm__ volatile (LOCK_IF_MP(%4) &quot;cmpxchgl %1,(%3)&quot; : &quot;=a&quot; (exchange_value) : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp) : &quot;cc&quot;, &quot;memory&quot;); return exchange_value;&#125; jdk8u: os.hpp is_MP() 12345678910static inline bool is_MP() &#123; // During bootstrap if _processor_count is not yet initialized // we claim to be MP as that is safest. If any platform has a // stub generator that might be triggered in this phase and for // which being declared MP when in fact not, is a problem - then // the bootstrap routine for the stub generator needs to check // the processor count directly and leave the bootstrap routine // in place until called after initialization has ocurred. return (_processor_count != 1) || AssumeMP;&#125; jdk8u: atomic_linux_x86.inline.hpp 1#define LOCK_IF_MP(mp) &quot;cmp $0, &quot; #mp &quot;; je 1f; lock; 1: &quot; 最终实现： cmpxchg = cas修改变量值 1lock cmpxchg 指令 硬件： lock指令在执行后面指令的时候锁定一个北桥信号 （不采用锁总线的方式） markword工具：JOL = Java Object Layout12345678&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; jdk8u: markOop.hpp 1234567891011121314151617181920// Bit-format of an object header (most significant first, big endian layout below)://// 32 bits:// --------// hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object)// size:32 ------------------------------------------&gt;| (CMS free block)// PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)//// 64 bits:// --------// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)// size:64 -----------------------------------------------------&gt;| (CMS free block)//// unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block) synchronized的横切面详解 synchronized原理 升级过程 汇编实现 vs reentrantLock的区别 java源码层级synchronized(o) 字节码层级monitorenter moniterexit JVM层级（Hotspot）12345678910111213package com.mashibing.insidesync;import org.openjdk.jol.info.ClassLayout;public class T01_Sync1 &#123; public static void main(String[] args) &#123; Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 12345678com.mashibing.insidesync.T01_Sync1$Lock object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 49 ce 00 20 (01001001 11001110 00000000 00100000) (536923721) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 12345678com.mashibing.insidesync.T02_Sync2$Lock object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 90 2e 1e (00000101 10010000 00101110 00011110) (506368005) 4 4 (object header) 1b 02 00 00 (00011011 00000010 00000000 00000000) (539) 8 4 (object header) 49 ce 00 20 (01001001 11001110 00000000 00100000) (536923721) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes tota InterpreterRuntime:: monitorenter方法 12345678910111213141516171819202122IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) &#123; Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); &#125; Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), &quot;must be NULL or an object&quot;); if (UseBiasedLocking) &#123; // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); &#125; else &#123; ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); &#125; assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), &quot;must be NULL or an object&quot;);#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END synchronizer.cpp revoke_and_rebias 12345678910111213141516void ObjectSynchronizer::fast_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) &#123; if (UseBiasedLocking) &#123; if (!SafepointSynchronize::is_at_safepoint()) &#123; BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) &#123; return; &#125; &#125; else &#123; assert(!attempt_rebias, &quot;can not rebias toward VM thread&quot;); BiasedLocking::revoke_at_safepoint(obj); &#125; assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); &#125; slow_enter (obj, lock, THREAD) ;&#125; 123456789101112131415161718192021222324252627282930313233343536void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) &#123; markOop mark = obj-&gt;mark(); assert(!mark-&gt;has_bias_pattern(), &quot;should not see bias pattern here&quot;); if (mark-&gt;is_neutral()) &#123; // Anticipate successful CAS -- the ST of the displaced mark must // be visible &lt;= the ST performed by the CAS. lock-&gt;set_displaced_header(mark); if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-&gt;mark_addr(), mark)) &#123; TEVENT (slow_enter: release stacklock) ; return ; &#125; // Fall through to inflate() ... &#125; else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) &#123; assert(lock != mark-&gt;locker(), &quot;must not re-lock the same lock&quot;); assert(lock != (BasicLock*)obj-&gt;mark(), &quot;don&#x27;t relock with same BasicLock&quot;); lock-&gt;set_displaced_header(NULL); return; &#125;#if 0 // The following optimization isn&#x27;t particularly useful. if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor()-&gt;is_entered(THREAD)) &#123; lock-&gt;set_displaced_header (NULL) ; return ; &#125;#endif // The object header will never be displaced to this lock, // so it does not matter what the value is, except that it // must be non-zero to avoid looking like a re-entrant lock, // and must not look locked either. lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::inflate(THREAD, obj())-&gt;enter(THREAD);&#125; inflate方法：膨胀为重量级锁 锁升级过程JDK8 markword实现表： 自旋锁什么时候升级为重量级锁？ 为什么有自旋锁还需要重量级锁？ 自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗 重量级锁有等待队列，所有拿不到锁的进入等待队列，不需要消耗CPU资源 偏向锁是否一定比自旋锁效率高？ 不一定，在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用自旋锁 JVM启动过程，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开 new - 偏向锁 - 轻量级锁 （无锁, 自旋锁，自适应自旋）- 重量级锁 synchronized优化的过程和markword息息相关 用markword中最低的三位代表锁状态 其中1位是偏向锁位 两位是普通锁位 Object o = new Object()锁 = 0 01 无锁态注意：如果偏向锁打开，默认是匿名偏向状态 o.hashCode()001 + hashcode 1200000001 10101101 00110100 0011011001011001 00000000 00000000 00000000 little endian big endian 00000000 00000000 00000000 01011001 00110110 00110100 10101101 00000000 默认synchronized(o)00 -&gt; 轻量级锁默认情况 偏向锁有个时延，默认是4秒why? 因为JVM虚拟机自己有一些默认启动的线程，里面有好多sync代码，这些sync代码启动时就知道肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作，效率较低。 1-XX:BiasedLockingStartupDelay=0 如果设定上述参数new Object () - &gt; 101 偏向锁 -&gt;线程ID为0 -&gt; Anonymous BiasedLock打开偏向锁，new出来的对象，默认就是一个可偏向匿名对象101 如果有线程上锁上偏向锁，指的就是，把markword的线程ID改为自己线程ID的过程偏向锁不可重偏向 批量偏向 批量撤销 如果有线程竞争撤销偏向锁，升级轻量级锁线程在自己的线程栈生成LockRecord ，用CAS操作将markword设置为指向自己这个线程的LR的指针，设置成功者得到锁 如果竞争加剧竞争加剧：有线程超过10次自旋， -XX:PreBlockSpin， 或者自旋线程数超过CPU核数的一半， 1.6之后，加入自适应自旋 Adapative Self Spinning ， JVM自己控制升级重量级锁：-&gt; 向操作系统申请资源，linux mutex , CPU从3级-0级系统调用，线程挂起，进入等待队列，等待操作系统的调度，然后再映射回用户空间 (以上实验环境是JDK11，打开就是偏向锁，而JDK8默认对象头是无锁) 偏向锁默认是打开的，但是有一个时延，如果要观察到偏向锁，应该设定参数 如果计算过对象的hashCode，则对象无法进入偏向状态！ 轻量级锁重量级锁的hashCode存在与什么地方？ 答案：线程栈中，轻量级锁的LR中，或是代表重量级锁的ObjectMonitor的成员中 关于epoch: (不重要) 批量重偏向与批量撤销渊源：从偏向锁的加锁解锁过程中可看出，当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe point时，再将偏向锁撤销为无锁状态或升级为轻量级，会消耗一定的性能，所以在多线程竞争频繁的情况下，偏向锁不仅不能提高性能，还会导致性能下降。于是，就有了批量重偏向与批量撤销的机制。 原理以class为单位，为每个class维护解决场景批量重偏向（bulk rebias）机制是为了解决：一个线程创建了大量对象并执行了初始的同步操作，后来另一个线程也来将这些对象作为锁对象进行操作，这样会导致大量的偏向锁撤销操作。批量撤销（bulk revoke）机制是为了解决：在明显多线程竞争剧烈的场景下使用偏向锁是不合适的。 一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个值达到重偏向阈值（默认20）时，JVM就认为该class的偏向锁有问题，因此会进行批量重偏向。每个class对象会有一个对应的epoch字段，每个处于偏向锁状态对象的Mark Word中也有该字段，其初始值为创建该对象时class中的epoch的值。每次发生批量重偏向时，就将该值+1，同时遍历JVM中所有线程的栈，找到该class所有正处于加锁状态的偏向锁，将其epoch字段改为新值。下次获得锁时，发现当前对象的epoch值和class的epoch不相等，那就算当前已经偏向了其他线程，也不会执行撤销操作，而是直接通过CAS操作将其Mark Word的Thread Id 改成当前线程Id。当达到重偏向阈值后，假设该class计数器继续增长，当其达到批量撤销的阈值后（默认40），JVM就认为该class的使用场景存在多线程竞争，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑。 没错，我就是厕所所长 加锁，指的是锁定对象 锁升级的过程 JDK较早的版本 OS的资源 互斥量 用户态 -&gt; 内核态的转换 重量级 效率比较低 现代版本进行了优化 无锁 - 偏向锁 -轻量级锁（自旋锁）-重量级锁 偏向锁 - markword 上记录当前线程指针，下次同一个线程加锁的时候，不需要争用，只需要判断线程指针是否同一个，所以，偏向锁，偏向加锁的第一个线程 。hashCode备份在线程栈上 线程销毁，锁降级为无锁 有争用 - 锁升级为轻量级锁 - 每个线程有自己的LockRecord在自己的线程栈上，用CAS去争用markword的LR的指针，指针指向哪个线程的LR，哪个线程就拥有锁 自旋超过10次，升级为重量级锁 - 如果太多线程自旋 CPU消耗过大，不如升级为重量级锁，进入等待队列（不消耗CPU）-XX:PreBlockSpin 自旋锁在 JDK1.4.2 中引入，使用 -XX:+UseSpinning 来开启。JDK 6 中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应自旋锁意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 偏向锁由于有锁撤销的过程revoke，会消耗系统资源，所以，在锁争用特别激烈的时候，用偏向锁未必效率高。还不如直接使用轻量级锁。 锁重入sychronized是可重入锁 重入次数必须记录，因为要解锁几次必须得对应 偏向锁 自旋锁 -&gt; 线程栈 -&gt; LR + 1 重量级锁 -&gt; ? ObjectMonitor字段上 synchronized最底层实现12345678910111213141516public class T &#123; static volatile int i = 0; public static void n() &#123; i++; &#125; public static synchronized void m() &#123;&#125; publics static void main(String[] args) &#123; for(int j=0; j&lt;1000_000; j++) &#123; m(); n(); &#125; &#125;&#125; java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly T C1 Compile Level 1 (一级优化) C2 Compile Level 2 (二级优化) 找到m() n()方法的汇编码，会看到 lock comxchg …..指令 synchronized vs Lock (CAS)123456在高争用 高耗时的环境下synchronized效率更高在低争用 低耗时的环境下CAS效率更高synchronized到重量级之后是等待队列（不消耗CPU）CAS（等待期间消耗CPU）一切以实测为准 锁消除 lock eliminate1234public void add(String str1,String str2)&#123; StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2);&#125; 我们都知道 StringBuffer 是线程安全的，因为它的关键方法都是被 synchronized 修饰过的，但我们看上面这段代码，我们会发现，sb 这个引用只会在 add 方法中使用，不可能被其它线程引用（因为是局部变量，栈私有），因此 sb 是不可能共享的资源，JVM 会自动消除 StringBuffer 对象内部的锁。 锁粗化 lock coarsening12345678910public String test(String str)&#123; int i = 0; StringBuffer sb = new StringBuffer(): while(i &lt; 100)&#123; sb.append(str); i++; &#125; return sb.toString():&#125; JVM 会检测到这样一连串的操作都对同一个对象加锁（while 循环内 100 次执行 append，没有锁粗化的就要进行 100 次加锁/解锁），此时 JVM 就会将加锁的范围粗化到这一连串的操作的外部（比如 while 虚幻体外），使得这一连串操作只需要加一次锁即可。 锁降级（不重要）https://www.zhihu.com/question/63859501 其实，只被VMThread访问，降级也就没啥意义了。所以可以简单认为锁降级不存在！ 超线程一个ALU + 两组Registers + PC 参考资料http://openjdk.java.net/groups/hotspot/docs/HotSpotGlossary.html volatile的用途1.线程可见性12345678910111213141516171819package com.mashibing.testvolatile;public class T01_ThreadVisibility &#123; private static volatile boolean flag = true; public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt; &#123; while (flag) &#123; //do sth &#125; System.out.println(&quot;end&quot;); &#125;, &quot;server&quot;).start(); Thread.sleep(1000); flag = false; &#125;&#125; 2.防止指令重排序问题：DCL单例需不需要加volatile？CPU的基础知识 缓存行对齐缓存行64个字节是CPU同步的基本单位，缓存行隔离会比伪共享效率要高Disruptor 需要注意，JDK8引入了@sun.misc.Contended注解，来保证缓存行隔离效果要使用此注解，必须去掉限制参数：-XX:-RestrictContended 另外，java编译器或者JIT编译器有可能会去除没用的字段，所以填充字段必须加上volatile 12345678910111213141516171819202122232425262728293031323334353637383940package com.mashibing.juc.c_028_FalseSharing; public class T02_CacheLinePadding &#123; private static class Padding &#123; public volatile long p1, p2, p3, p4, p5, p6, p7; // &#125; private static class T extends Padding &#123; public volatile long x = 0L; &#125; public static T[] arr = new T[2]; static &#123; arr[0] = new T(); arr[1] = new T(); &#125; public static void main(String[] args) throws Exception &#123; Thread t1 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_0000L; i++) &#123; arr[0].x = i; &#125; &#125;); Thread t2 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_0000L; i++) &#123; arr[1].x = i; &#125; &#125;); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println((System.nanoTime() - start)/100_0000); &#125; &#125; MESI 伪共享 合并写CPU内部的4个字节的Buffer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.mashibing.juc.c_029_WriteCombining;public final class WriteCombining &#123; private static final int ITERATIONS = Integer.MAX_VALUE; private static final int ITEMS = 1 &lt;&lt; 24; private static final int MASK = ITEMS - 1; private static final byte[] arrayA = new byte[ITEMS]; private static final byte[] arrayB = new byte[ITEMS]; private static final byte[] arrayC = new byte[ITEMS]; private static final byte[] arrayD = new byte[ITEMS]; private static final byte[] arrayE = new byte[ITEMS]; private static final byte[] arrayF = new byte[ITEMS]; public static void main(final String[] args) &#123; for (int i = 1; i &lt;= 3; i++) &#123; System.out.println(i + &quot; SingleLoop duration (ns) = &quot; + runCaseOne()); System.out.println(i + &quot; SplitLoop duration (ns) = &quot; + runCaseTwo()); &#125; &#125; public static long runCaseOne() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125; public static long runCaseTwo() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; &#125; i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125;&#125; 指令重排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.mashibing.jvm.c3_jmm;public class T04_Disorder &#123; private static int x = 0, y = 0; private static int a = 0, b =0; public static void main(String[] args) throws InterruptedException &#123; int i = 0; for(;;) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(new Runnable() &#123; public void run() &#123; //由于线程one先启动，下面这句话让它等一等线程two. 读着可根据自己电脑的实际性能适当调整等待时间. //shortWait(100000); a = 1; x = b; &#125; &#125;); Thread other = new Thread(new Runnable() &#123; public void run() &#123; b = 1; y = a; &#125; &#125;); one.start();other.start(); one.join();other.join(); String result = &quot;第&quot; + i + &quot;次 (&quot; + x + &quot;,&quot; + y + &quot;）&quot;; if(x == 0 &amp;&amp; y == 0) &#123; System.err.println(result); break; &#125; else &#123; //System.out.println(result); &#125; &#125; &#125; public static void shortWait(long interval)&#123; long start = System.nanoTime(); long end; do&#123; end = System.nanoTime(); &#125;while(start + interval &gt;= end); &#125;&#125; 系统底层如何实现数据一致性 MESI如果能解决，就使用MESI 如果不能，就锁总线 系统底层如何保证有序性 内存屏障sfence mfence lfence等系统原语 锁总线 volatile如何解决指令重排序1: volatile i 2: ACC_VOLATILE 3: JVM的内存屏障 ​ 屏障两边的指令不可以重排！保障有序！ ​ happends-before ​ as - if - serial 4：hotspot实现 bytecodeinterpreter.cpp 12345int field_offset = cache-&gt;f2_as_index(); if (cache-&gt;is_volatile()) &#123; if (support_IRIW_for_not_multiple_copy_atomic_cpu) &#123; OrderAccess::fence(); &#125; orderaccess_linux_x86.inline.hpp 12345678910inline void OrderAccess::fence() &#123; if (os::is_MP()) &#123; // always use locked addl since mfence is sometimes expensive#ifdef AMD64 __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);#else __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);#endif &#125;&#125; LOCK 用于在多处理器中执行指令时对共享内存的独占使用。它的作用是能够将当前处理器对应缓存的内容刷新到内存，并使其他处理器对应的缓存失效。另外还提供了有序的指令无法越过这个内存屏障的作用。 用hsdis观察synchronized和volatile 安装hsdis (自行百度) 代码 12345678910111213141516171819public class T &#123; public static volatile int i = 0; public static void main(String[] args) &#123; for(int i=0; i&lt;1000000; i++) &#123; m(); n(); &#125; &#125; public static synchronized void m() &#123; &#125; public static void n() &#123; i = 1; &#125;&#125; java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly T &gt; 1.txt &lt;!--code￼30--&gt;","categories":[{"name":"多线程","slug":"多线程","permalink":"https://lingxizz.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://lingxizz.github.io/tags/%E9%94%81/"}]}],"categories":[{"name":"Linux","slug":"Linux","permalink":"https://lingxizz.github.io/categories/Linux/"},{"name":"计算机基础","slug":"计算机基础","permalink":"https://lingxizz.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"多线程","permalink":"https://lingxizz.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://lingxizz.github.io/tags/Linux/"},{"name":"操作系统","slug":"操作系统","permalink":"https://lingxizz.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://lingxizz.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"volatile","slug":"volatile","permalink":"https://lingxizz.github.io/tags/volatile/"},{"name":"锁","slug":"锁","permalink":"https://lingxizz.github.io/tags/%E9%94%81/"}]}